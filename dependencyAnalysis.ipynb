{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/core/errors.py:160: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn('unable to install sys.excepthook to format Scenic backtraces')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scenic\n",
    "\n",
    "# ### NuScenes Query\n",
    "# from scenic.simulators.carla.nusc_query_api import NuscQueryAPI\n",
    "# nusc = NuscQueryAPI(version='v1.0-trainval', \\\n",
    "#                     dataroot='/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependency Analysis\n",
    "def cacheExprTreeNodes(attribute, nodeSet=None):\n",
    "    \"\"\"cache all the nodes of the input attribute's expression tree to the dictionary\"\"\"\n",
    "    if nodeSet is None:\n",
    "        nodeSet = set()\n",
    "    nodeSet.add(attribute)\n",
    "    if attribute._dependencies == ():\n",
    "        return nodeSet\n",
    "    for dep in attribute._dependencies:\n",
    "        cacheExprTreeNodes(dep, nodeSet)\n",
    "    return nodeSet\n",
    "\n",
    "def cacheAttributes(scenario, attributeList):\n",
    "    dictionary = {}\n",
    "    dictionary['objAttributes_names'] = []\n",
    "    dictionary['positionAttributes_names'] = []\n",
    "    dictionary['headingAttributes_names'] = []\n",
    "    \n",
    "    # cache all object attributes\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[i]\n",
    "        obj_name = 'obj'+str(i)\n",
    "        dictionary[obj_name] = {}\n",
    "        \n",
    "        for attribute in attributeList:\n",
    "            dictionary[obj_name][attribute] = {}\n",
    "            dictionary[obj_name][attribute]['self'] = getattr(obj, attribute)\n",
    "            dictionary[obj_name][attribute]['set'] = cacheExprTreeNodes(getattr(obj, attribute), None)\n",
    "            dictionary[obj_name][attribute]['intermediate_variables_set'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attributes_objs'] = set()\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attributes_objs'] = set()\n",
    "            dictionary['objAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'position':\n",
    "                dictionary['positionAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'heading':\n",
    "                dictionary['headingAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "                \n",
    "    return dictionary\n",
    "\n",
    "def checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "    \"\"\" checks whether the two attr1 and attr2 are jointly dependent on an intermediate variable\n",
    "    or is both dependent on another attribute. \n",
    "    Output:\n",
    "    True, if attr1 and attr2 are \"dependent\" on another attribute, not intermediate variable\n",
    "    False, attr1 and attr2 are both \"jointly dependent\" on an intermediate variable\n",
    "    \"\"\"\n",
    "    [obj1_name, attr1] = attr1_name.split('_')\n",
    "    attr1_obj = dictionary[obj1_name][attr1]['self']\n",
    "    attr1_jointly_dep_attr_names = dictionary[obj1_name][attr1]['jointly_dependent_attribute_names']\n",
    "    [obj2_name, attr2] = attr2_name.split('_')\n",
    "    attr2_obj = dictionary[obj2_name][attr2]['self']\n",
    "    attr2_jointly_dep_attr_names = dictionary[obj2_name][attr2]['jointly_dependent_attribute_names']\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr1_name: \", attr1_name)\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr2_name: \", attr2_name)\n",
    "    original_intersection = intersection\n",
    "    \n",
    "    objAttributes_names = dictionary['objAttributes_names'] \n",
    "    for attr_name in objAttributes_names:\n",
    "        if attr_name == attr1_name:\n",
    "            continue\n",
    "        elif attr_name == attr2_name:\n",
    "            break\n",
    "        else:\n",
    "            [obj_name, attr] = attr_name.split('_')\n",
    "            attr_obj = dictionary[obj_name][attr]['self']\n",
    "            attr_depSet = dictionary[obj_name][attr]['dependent_attribute_names']\n",
    "            \n",
    "            if attr_obj in original_intersection and attr_name not in attr1_jointly_dep_attr_names \\\n",
    "                and attr_name not in attr2_jointly_dep_attr_names: \n",
    "#                 print(\"other attr_name in the intersection: \", attr_name)\n",
    "                attr_cachedSet = dictionary[obj_name][attr]['set']\n",
    "                original_intersection = original_intersection - attr_cachedSet\n",
    "#                 print(\"len(original_intersection): \", len(original_intersection))\n",
    "                if len(original_intersection) == 0:\n",
    "#                     print(\"returns True\")\n",
    "                    # the intersection is another attribute\n",
    "                    return True\n",
    "    return False\n",
    "        \n",
    "def findAttribute(other_attr_obj, attr_dict, dictionary):\n",
    "    for obj_attr in attr_dict['dependent_attribute_names']:\n",
    "        [obj, attr] = obj_attr.split(\"_\")\n",
    "        if other_attr_obj is dictionary[obj][attr]['self']:\n",
    "            return obj_attr\n",
    "    return None\n",
    "\n",
    "def checkIntermediateSetMembership(attr_obj, attrIntermediateList):\n",
    "    for intermediateSet in attrIntermediateList:\n",
    "        if attr_obj in intermediateSet:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def analysis(objAttributes_names, dictionary):\n",
    "    for i in range(len(objAttributes_names)):\n",
    "        for j in range(len(objAttributes_names)):\n",
    "            if i < j:\n",
    "                attr1_name = objAttributes_names[i]\n",
    "                attr2_name = objAttributes_names[j]\n",
    "                [obj_name1, attr1] = attr1_name.split('_')\n",
    "                [obj_name2, attr2] = attr2_name.split('_')\n",
    "        \n",
    "                attribute1 = dictionary[obj_name1][attr1]\n",
    "                attribute2 = dictionary[obj_name2][attr2]\n",
    "                attr1_obj = attribute1['self']\n",
    "                attr2_obj = attribute2['self']\n",
    "                \n",
    "                set1 = attribute1['set']\n",
    "                set2 = attribute2['set']\n",
    "                intersection = set1.intersection(set2)\n",
    "                \n",
    "                if attr1_obj in intersection and attr1_obj not in attribute2['dependent_attributes_objs']:\n",
    "                    # attr2_obj is dependent on attr1_obj\n",
    "                    attribute2['dependent_attribute_names'].append(attr1_name)\n",
    "                    attribute2['dependent_attributes_objs'].add(attr1_obj)\n",
    "                elif attr2_obj in intersection and attr2_obj not in attribute1['dependent_attributes_objs']:\n",
    "                    # jointly_dependent case (e.g. depedendencyAnalysisTest4.scenic)\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "                        \n",
    "                elif len(intersection) > 0 \\\n",
    "                    and attr1_obj not in intersection and attr2_obj not in intersection \\\n",
    "                    and not checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "                    # the two attributes are jointly dependent (i.e. share intermediate variable(s))\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "                    \n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    return dictionary\n",
    "    \n",
    "def dependencyAnalysis(scenario, attributeList):\n",
    "    dictionary = cacheAttributes(scenario, attributeList)\n",
    "    dictionary['numberOfObjects'] = len(scenario.original_objects)\n",
    "    objAttributes_names = dictionary['objAttributes_names']\n",
    "    dictionary = analysis(objAttributes_names, dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def sortDependency(dictionary, scenario, monolithic_translation=False):\n",
    "    output = []\n",
    "    covered_attributes = []\n",
    "    \n",
    "    if not monolithic_translation:\n",
    "        for elem in dictionary['objAttributes_names']:\n",
    "            if elem in covered_attributes:\n",
    "                continue\n",
    "            covered_attributes.append(elem)\n",
    "            [obj_name, attr_name] = elem.split(\"_\")\n",
    "            joint_dep_set = dictionary[obj_name][attr_name]['jointly_dependent_attribute_names']\n",
    "            if len(joint_dep_set) > 0:\n",
    "                jointly_dependent_list = [elem]\n",
    "\n",
    "                for j in joint_dep_set:\n",
    "                    [j_obj_name, j_attr] = j.split(\"_\")\n",
    "                    jointly_dependent_list.append(j)\n",
    "                    covered_attributes.append(j)\n",
    "                output.append(jointly_dependent_list)\n",
    "            else:\n",
    "                output.append([elem])\n",
    "    else:\n",
    "        output = [(dictionary['objAttributes_names'])]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Test Dependency Analysis\n",
    "\n",
    "# attributeList = ['position', 'heading']\n",
    "# d = dependencyAnalysis(scenario, attributeList)\n",
    "# print(sortDependency(d, scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SMT Translation Pipeline\n",
    "\n",
    "from scenic.core.regions import SectorRegion\n",
    "from scenic.core.vectors import OrientedVector, Vector\n",
    "from scenic.core.distributions import *\n",
    "from scenic.domains.driving.roads import Network\n",
    "from scenic.core.regions import PointInRegionDistribution\n",
    "from scenic.core.type_support import TypecheckedDistribution\n",
    "import subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def resetConditionedVar(obj):\n",
    "    obj._conditioned = obj\n",
    "    if (obj._dependencies is None):\n",
    "        return None\n",
    "    for dep in obj._dependencies:\n",
    "        resetConditionedVar(dep)\n",
    "    return None\n",
    "\n",
    "def unconditionAllAttributes(scenario):\n",
    "    for obj in scenario.objects:\n",
    "        resetConditionedVar(obj.position)\n",
    "        resetConditionedVar(obj.heading)\n",
    "        \n",
    "def extractLabelAttribute(label, obj_index, attribute_name, objType, dataType, correspondence, egoObjIndex):\n",
    "    # Extract specific attribute from a label generated from a scenic program\n",
    "    output = None\n",
    "    if obj_index != egoObjIndex:\n",
    "        if obj_index > egoObjIndex:\n",
    "            obj_index -= 1\n",
    "#         print(\"extractLabelAttribute()\")\n",
    "#         print(\"label[objType]: \", label[objType])\n",
    "#         print(\"correspondence: \", correspondence)\n",
    "#         print(\"correspondence[obj_index]: \", correspondence[obj_index])\n",
    "#         print(\"attribute_name: \", attribute_name)\n",
    "        output = label[objType][correspondence[obj_index]][attribute_name]\n",
    "        if attribute_name == 'position':\n",
    "            return Vector(output[0], output[1])\n",
    "    else:\n",
    "        output = label['EgoCar'][attribute_name]\n",
    "        if attribute_name == 'position':\n",
    "            return Vector(output[0], output[1])\n",
    "    assert(output is not None)\n",
    "    if dataType == 'nuScenes':\n",
    "        output = math.radians(output+90) #90 deg added to reorient to Scenic's global coordinate system\n",
    "    return output\n",
    "        \n",
    "def initializeSMTFile(smt_file_path):\n",
    "    if os.path.isfile(smt_file_path):\n",
    "        os.remove(smt_file_path)\n",
    "    \n",
    "    open(smt_file_path, 'w').close()\n",
    "    writeSMTtoFile(smt_file_path, '(set-logic QF_NRA)')\n",
    "    \n",
    "def resetDictionary(cached_variables, smt_file_path):\n",
    "    regionAroundEgo = cached_variables['regionAroundEgo']\n",
    "    cached_variables.clear()\n",
    "    cached_variables['variables'] = []\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "\n",
    "def translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                   dictionary, errorBound, debug=False):\n",
    "    \n",
    "    x_error_margin = str(errorBound['x'])\n",
    "    y_error_margin = str(errorBound['y'])\n",
    "    heading_error_margin = str(errorBound['heading'])\n",
    "    \n",
    "    ## TODO: add error bound range to attributes\n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    obj_name, attr_type = attribute_name.split(\"_\")\n",
    "\n",
    "    # Encode the given attribute's expression tree\n",
    "    smt_var = attr_obj.encodeToSMT(smt_file_path, cached_variables, debug = debug)\n",
    "    \n",
    "    if attr_type == 'position':\n",
    "        assert(isinstance(attr_label, Vector))\n",
    "        x, y = smt_var\n",
    "        (x_label, y_label) = (str(attr_label.x), str(attr_label.y))\n",
    "        x_cond1 = smt_lessThanEq(smt_subtract(x_label, x_error_margin), x)\n",
    "        x_cond2 = smt_lessThanEq(x, smt_add(x_label, x_error_margin))\n",
    "        x_cond = smt_and(x_cond1, x_cond2)\n",
    "        \n",
    "        y_cond1 = smt_lessThanEq(smt_subtract(y_label, y_error_margin), y)\n",
    "        y_cond2 = smt_lessThanEq(y, smt_add(y_label, y_error_margin))\n",
    "        y_cond = smt_and(y_cond1, y_cond2)\n",
    "        \n",
    "#         (x_cond, y_cond) = vector_operation_smt((x_label, y_label), \"equal\",smt_var)\n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_and(x_cond, y_cond)))\n",
    "    else:\n",
    "        heading_label = str(attr_label)\n",
    "        heading_cond1 = smt_lessThanEq(smt_subtract(heading_label, heading_error_margin), smt_var)\n",
    "        heading_cond2 = smt_lessThanEq(smt_var, smt_add(heading_label, heading_error_margin))\n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_and(heading_cond1, heading_cond2)))\n",
    "#         writeSMTtoFile(smt_file_path, smt_assert(None, smt_equal(str(attr_label), smt_var)))\n",
    "        \n",
    "def findObjType(obj):\n",
    "    if \"Car\" in str(obj) or \"Truck\" in str(obj) or \"Motorcycle\" in str(obj) or \"Bicycle\" in str(obj):\n",
    "        return \"Vehicles\"\n",
    "    elif \"Pedestrian\" in str(obj):\n",
    "        return \"Pedestrians\"\n",
    "    elif \"Cone\" in str(obj):\n",
    "        return \"Objects\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return None\n",
    "\n",
    "def conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence, \\\n",
    "                        egoObjIndex, label):\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence, \\\n",
    "                                              egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "        print(\"conditionAttributes attribute: \", attribute_name)\n",
    "        print(\"conditionAttributes attr_label: \", attr_label)\n",
    "        if isinstance(attr_label, float) or isinstance(attr_label, int):\n",
    "            attr_obj.conditionTo(Constant(attr_label))\n",
    "        elif isinstance(attr_obj, PointInRegionDistribution):\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "            if isinstance(attr_obj.region, TypecheckedDistribution): \n",
    "                attr_obj.region.dist.conditionTo(attr_label)\n",
    "            else:\n",
    "                attr_obj.region.conditionTo(attr_label)\n",
    "        else:\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "\n",
    "def validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                         correspondence, egoObjIndex, dataType, errorBound, debug=False, falseTesting=False,\\\n",
    "                        monolithic_translation=False):\n",
    "    \n",
    "    count = 0\n",
    "    ## translate jointly dependent attribute expression trees\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        count += 1\n",
    "        if count >= 2:\n",
    "            break\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence,\\\n",
    "                                          egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "\n",
    "        translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                          dictionary, errorBound, debug)\n",
    "        print(\"validateLabelElement encoding done for validateLabelElement: \", attribute_name)\n",
    "#         if monolithic_translation:\n",
    "#             print(\"validLabelElement: Monolithic translation case -- condition attribute: \",attribute_name)\n",
    "#             conditionAttributes([attribute_name], dictionary, scenario, dataType, correspondence, \\\n",
    "#                         egoObjIndex, label)\n",
    "    \n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    writeSMTtoFile(smt_file_path, \"(check-sat)\")\n",
    "    writeSMTtoFile(smt_file_path, \"(exit)\")\n",
    "\n",
    "    if subprocess.call(\"./run_smt_encoding.sh\") == 1:\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def generateObjectMatchingCorrespondenceSet(scenario):\n",
    "    objTypeOrder = []\n",
    "    objTypeDict = {}\n",
    "    \n",
    "    for obj in scenario.original_objects:\n",
    "        if obj is not scenario.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objTypeOrder.append(objType)\n",
    "\n",
    "            if objType not in objTypeDict.keys():\n",
    "                objTypeDict[objType] = {}\n",
    "                objTypeDict[objType]['count'] = 1\n",
    "            else:\n",
    "                objTypeDict[objType]['count'] += 1\n",
    "    \n",
    "#     print(\"objTypeOrder: \", objTypeOrder)\n",
    "    \n",
    "    total_permutation_number = 1\n",
    "    for objType in objTypeDict.keys():\n",
    "        count = objTypeDict[objType]['count']\n",
    "        index_list = [i for i in range(count)]\n",
    "        objTypeDict[objType]['correspondence'] = list(itertools.permutations(index_list))\n",
    "        total_permutation_number *= len(objTypeDict[objType]['correspondence'])\n",
    "    \n",
    "#     print(\"total_permutation_number: \", total_permutation_number)\n",
    "#     print(\"objTypeDict['Vehicles']['count']: \", objTypeDict['Vehicles']['count'])\n",
    "#     print(\"objTypeDict['Vehicles']['correspondence']: \", objTypeDict['Vehicles']['correspondence'])\n",
    "#     print(\"len(objTypeDict['Vehicles']['correspondence']): \", len(objTypeDict['Vehicles']['correspondence']))\n",
    "#     print(\"objTypeDict['Pedestrians']['count']\", objTypeDict['Pedestrians']['count'])\n",
    "#     print(\"objTypeDict['Pedestrians']['correspondence']\", objTypeDict['Pedestrians']['correspondence'])\n",
    "    \n",
    "    # sort the types by the number of counts\n",
    "    types = list(objTypeDict.keys())\n",
    "    counts = [objTypeDict[objType]['count'] for objType in types]\n",
    "    sorted_types = []\n",
    "    sorted_types_nums = []\n",
    "    \n",
    "    for i in range(len(types)):\n",
    "        elem = max(counts)\n",
    "        index = counts.index(max(counts))\n",
    "        sorted_types.append(types[index])\n",
    "        sorted_types_nums.append(elem)\n",
    "        del types[index]\n",
    "        del counts[index]\n",
    "    \n",
    "#     print(\"sorted_types: \", sorted_types)\n",
    "#     print(\"sorted_types_nums: \", sorted_types_nums)\n",
    "    \n",
    "    # compute the number of identical elements to insert per objType\n",
    "    num_identicals = []\n",
    "    for i in range(len(sorted_types)):\n",
    "        if i == len(sorted_types)-1:\n",
    "            num_identicals.append(1)\n",
    "        else:\n",
    "            num_identicals.append(np.prod(sorted_types_nums[i+1:]))\n",
    "#     print(\"num_identicals: \", num_identicals)\n",
    "    \n",
    "    # create combinations of correspondences in the order of objTypeOrder\n",
    "    correspondenceList = [[0]*len(objTypeOrder) for i in range(total_permutation_number)]\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "    for i in range(len(sorted_types) - 1):\n",
    "        objType = sorted_types[i]\n",
    "        index = 0\n",
    "#         print(\"objType: \", objType)\n",
    "        \n",
    "        for j in range(len(objTypeDict[objType]['correspondence'])):\n",
    "            correspondenceToEdit = correspondenceList[index]\n",
    "#             print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "            objTypeCorrespondence = objTypeDict[objType]['correspondence'][j]\n",
    "#             print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "            correspondence = createCorrespondence(correspondenceToEdit, objType, objTypeOrder, \\\n",
    "                                                  objTypeCorrespondence)\n",
    "#             print(\"correspondence: \", correspondence)\n",
    "            \n",
    "            for k in range(num_identicals[i]):\n",
    "                correspondenceList[index] = correspondence\n",
    "                index += 1\n",
    "    \n",
    "    finalCorrespondenceList = []\n",
    "    if len(sorted_types) > 1:\n",
    "        num_lastObjType_correspondence = len(objTypeDict[sorted_types[-1]]['correspondence'])\n",
    "#         print(\"num_lastObjType_correspondence: \", num_lastObjType_correspondence)\n",
    "        num_iteration = int(total_permutation_number / num_lastObjType_correspondence)\n",
    "#         print(\"num_iteration: \", num_iteration)\n",
    "        assert(total_permutation_number == num_iteration * num_lastObjType_correspondence)\n",
    "        lastObjType = sorted_types[-1]\n",
    "#         print(\"lastObjType: \", lastObjType)\n",
    "        index = 0\n",
    "        for m in range(num_iteration):\n",
    "            for n in range(num_lastObjType_correspondence):\n",
    "#                 print(\"index: \", index)\n",
    "                correspondenceToEdit = correspondenceList[index]\n",
    "#                 print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "                objTypeCorrespondence = objTypeDict[lastObjType]['correspondence'][n]\n",
    "#                 print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "                correspondence = createCorrespondence(correspondenceToEdit, lastObjType, objTypeOrder, objTypeCorrespondence)\n",
    "#                 print(\"correspondence: \", correspondence)\n",
    "                finalCorrespondenceList.append(tuple(correspondence))\n",
    "                index += 1\n",
    "    else:\n",
    "        finalCorrespondenceList = correspondenceList\n",
    "    \n",
    "    if finalCorrespondenceList == []: #case when there is only ego vehicle, no other obj\n",
    "        finalCorrespondenceList = [(0)]\n",
    "    return finalCorrespondenceList\n",
    "\n",
    "def createCorrespondence(correspondence, objType, objTypeOrder, objTypeCorrespondence):\n",
    "    index = 0\n",
    "    for i in range(len(objTypeOrder)):\n",
    "        if objTypeOrder[i] == objType:\n",
    "            correspondence[i] = objTypeCorrespondence[index]\n",
    "            index += 1\n",
    "            if index == len(objTypeCorrespondence):\n",
    "                break\n",
    "    return correspondence\n",
    "    \n",
    "\n",
    "def findEgoObjIndex(scenario):\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        if scenario.original_objects[i] is scenario.egoObject:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def validateLabel(scenario, label, map_path, map_source='carla', ego_visibleDistance = 50, ego_viewAngle = 360, \\\n",
    "                  smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'], \\\n",
    "                  debug = False):\n",
    "    #TODO: need to add object matching\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # Initialize smt file, if exists\n",
    "    initializeSMTFile(smt_file_path)\n",
    "    \n",
    "    # Create Ego's VisibleRegion\n",
    "    cached_variables = {}\n",
    "#     if map_source == 'carla':\n",
    "#         cached_variables['network'] = Network.fromFile(map_path, None)\n",
    "#     elif map_source == 'nuScenes':\n",
    "#         raise NotImplementedError\n",
    "#     else:\n",
    "#          raise NotImplementedError\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    label_ego_pos = label.egoObject.position\n",
    "    label_ego_heading = label.egoObject.heading\n",
    "    regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "                                    math.radians(ego_viewAngle))\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario)\n",
    "    print(\"sortedDependencyList: \", sortedDependencyList)\n",
    "    \n",
    "    for jointlyDependentAttributeList in sortedDependencyList:\n",
    "        print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "        if not validateLabelElement(scenario, cached_variables, jointlyDependentAttributeList, dictionary, debug):\n",
    "            print(\"NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "            return False\n",
    "        else: # condition attributes in jointlyDependentAttributeList\n",
    "            print(\".........................valid attribute: \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence,\\\n",
    "                                   label)\n",
    "            resetDictionary(cached_variables, regionAroundEgo, smt_file_path)\n",
    "    \n",
    "    ## Check Hard Constraint Satisfaction\n",
    "    if not scenario.checkRequirements():\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/6_agent_scenario.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# x = generateObjectMatchingCorrespondenceSet(scenario)\n",
    "# print(\"finalOutput: \", x)\n",
    "# print(len(x))\n",
    "# # print(len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Object Matching\n",
    "import math\n",
    "\n",
    "def conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    for obj_index in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[obj_index]\n",
    "        for attribute_name in attributeList:\n",
    "            objType = findObjType(obj)\n",
    "            attr_label = extractLabelAttribute(label, obj_index, attribute_name, objType, \\\n",
    "                                               dataType, correspondence, egoObjIndex)\n",
    "            if isinstance(attr_label, (float, int)):\n",
    "                attr_label = Constant(attr_label)\n",
    "            obj_attr = getattr(obj, attribute_name)\n",
    "            obj_attr.conditionTo(attr_label)\n",
    "\n",
    "def satisfyHardConstraints(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    unconditionAllAttributes(scenario)\n",
    "    conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType)\n",
    "    return scenario.checkRequirements()\n",
    "\n",
    "def scenarioObjClassCount(scenario):\n",
    "    # check whether the number of objects match per class\n",
    "    objClassCountDict = {}\n",
    "    for obj in scenario.original_objects:\n",
    "        objType = findObjType(obj)\n",
    "        if obj is not scenario.egoObject:\n",
    "            if objType not in objClassCountDict.keys():\n",
    "                objClassCountDict[objType] = {}\n",
    "                objClassCountDict[objType]['count'] = 1\n",
    "            else:\n",
    "                objClassCountDict[objType]['count'] += 1\n",
    "        else:\n",
    "            objClassCountDict['EgoCar'] = {}\n",
    "            objClassCountDict['EgoCar']['count'] = 1\n",
    "    return objClassCountDict\n",
    "\n",
    "def checkLabelValidity(label, objClassCountDict):\n",
    "    for objType in objClassCountDict.keys():\n",
    "        if objType == 'EgoCar':\n",
    "            continue\n",
    "        if len(label[objType]) != objClassCountDict[objType]['count']:\n",
    "            print(\"label[objType]: \", label[objType])\n",
    "            print(\"objClassCountDict[objType]['count']\")\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def queryLabelSetup(scenario, label, ego_visibleDistance = 50, ego_viewAngle = 360, \\\n",
    "                  smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'],\\\n",
    "                   dataType='carla', monolithic_translation=False):\n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # Create Ego's VisibleRegion\n",
    "    cached_variables = {}\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    (ego_x, ego_y) = label['EgoCar']['position']\n",
    "    label_ego_pos = Vector(ego_x, ego_y)\n",
    "    if dataType == 'carla':\n",
    "        label_ego_heading = label['EgoCar']['heading']\n",
    "    if dataType == 'nuScenes':\n",
    "        label_ego_heading = math.radians(label['EgoCar']['heading']+90)\n",
    "    regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "                                    math.radians(ego_viewAngle))\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    egoObjIndex = findEgoObjIndex(scenario)\n",
    "    objClassCountDict = scenarioObjClassCount(scenario)\n",
    "    \n",
    "    # Sort Attribute Dependency \n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario, monolithic_translation)\n",
    "    \n",
    "    # Compute All Correspondence\n",
    "    allObjCorrespondence = generateObjectMatchingCorrespondenceSet(scenario)\n",
    "    \n",
    "    outputDict = {}\n",
    "    outputDict['cached_variables'] = cached_variables\n",
    "    outputDict['sortedDependencyList'] = sortedDependencyList\n",
    "    outputDict['allObjCorrespondence'] = allObjCorrespondence\n",
    "    outputDict['egoObjIndex'] = egoObjIndex\n",
    "    outputDict['dictionary'] = dictionary\n",
    "    outputDict['objClassCountDict'] = objClassCountDict\n",
    "    outputDict['attributeList'] = attributeList\n",
    "    return outputDict\n",
    "    \n",
    "def queryLabel(scenario, label, outputDict, errorBound, dataType='carla', smt_file_path='./test_smt_encoding.smt2', \\\n",
    "               debug=False, monolithic_translation = False):\n",
    "    \n",
    "    objClassCountDict = outputDict['objClassCountDict']\n",
    "    print(\"objClassCountDict: \", objClassCountDict)\n",
    "    if not checkLabelValidity(label, objClassCountDict):\n",
    "        # number of objects do not match per class ==> reject the label\n",
    "        print(\"Obj Count does not match: Reject\")\n",
    "        return False\n",
    "    \n",
    "    cached_variables = outputDict['cached_variables']\n",
    "    sortedDependencyList = outputDict['sortedDependencyList']\n",
    "    allObjCorrespondence = outputDict['allObjCorrespondence']\n",
    "    print(\"allObjCorrespondence: \", allObjCorrespondence)\n",
    "    egoObjIndex = outputDict['egoObjIndex']\n",
    "    dictionary = outputDict['dictionary']\n",
    "    attributeList = outputDict['attributeList']\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # Initialize smt file, if exists\n",
    "    initializeSMTFile(smt_file_path)\n",
    "    \n",
    "    print(\"begin query\")\n",
    "    for correspondence in allObjCorrespondence:\n",
    "        failed = False\n",
    "        print(\"queryLabel correspondence: \", correspondence)\n",
    "        for jointlyDependentAttributeList in sortedDependencyList:\n",
    "            print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            if validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                                            correspondence, egoObjIndex, dataType, errorBound, debug=debug, \\\n",
    "                                            monolithic_translation=monolithic_translation):\n",
    "                print(\".........................valid attribute: \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "                conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, \\\n",
    "                                    correspondence, egoObjIndex, label)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "            else: # condition attributes in jointlyDependentAttributeList\n",
    "                print(\"NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "                failed = True\n",
    "                unconditionAllAttributes(scenario)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "                break\n",
    "\n",
    "        ## Check Hard Constraint Satisfaction\n",
    "        if not failed and satisfyHardConstraints(scenario, dictionary, label, attributeList, \\\n",
    "                                                 correspondence, egoObjIndex, dataType):\n",
    "            return True\n",
    "        if not failed:\n",
    "            print(\"hard constraint not satisfied\")\n",
    "\n",
    "    return False\n",
    "\n",
    "def convertScenicLabel(scenic_label):\n",
    "    label = {}\n",
    "    label['EgoCar'] = {}\n",
    "    ego_pos = scenic_label.egoObject.position\n",
    "    label['EgoCar']['position'] = (ego_pos[0], ego_pos[1])\n",
    "    label['EgoCar']['heading'] = scenic_label.egoObject.heading\n",
    "    label['Vehicles'] = []\n",
    "    label['Pedestrians'] = []\n",
    "    label['Objects'] = []\n",
    "    for obj in scenic_label.objects:\n",
    "        if obj is not scenic_label.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objDict = {}\n",
    "            objPos = obj.position\n",
    "            objDict['position'] = (objPos[0], objPos[1])\n",
    "            objDict['heading'] = obj.heading\n",
    "            label[objType].append(objDict)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "\n",
    "# directory = '/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data/experiment_results'\n",
    "# subject1 = 'experiment_result_JayShenoy'\n",
    "# subject2 = 'experiment_result_TaeSung'\n",
    "# subject3 = 'experiment_result_Xiangyu'\n",
    "# scenario_list = ['scenario1','scenario2','scenario3','scenario4','scenario5']\n",
    "# dir3 = os.path.join(directory, 'scenario1_queried')\n",
    "# # dir3 = os.path.join(directory, subject3, 'scenario3')\n",
    "# filenames = [file for file in os.listdir(dir3) if file.endswith('.jpg')]\n",
    "# img_name = filenames[0]\n",
    "# label = nusc.get_img_data(img_name)\n",
    "# ego_label = label['EgoCar']\n",
    "# vehicles_label = label['Vehicles']\n",
    "# pedestrians_label = label['Pedestrians']\n",
    "# # print(ego_label)\n",
    "# # print(vehicles_label)\n",
    "# # print(pedestrians_label)\n",
    "# count = 0\n",
    "# # for file in filenames:\n",
    "# file = 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535728830362404.jpg'\n",
    "# count += 1\n",
    "# label = nusc.get_img_data(file)\n",
    "# outputDict = queryLabelSetup(scenario, label, ego_visibleDistance = 50, ego_viewAngle = 360, \\\n",
    "#                   smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'])\n",
    "\n",
    "# if not queryLabel(scenario, label, outputDict, dataType='nuScenes', debug=True):\n",
    "#     print(\"NON-VALID file: \", file)\n",
    "# #     break\n",
    "# else:\n",
    "#     print(\"Valid \"+str(count)+\": \", file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label generated:  2\n",
      "converted label:  {'EgoCar': {'position': (-123.54152888724414, 36.415417224546985), 'heading': 0.12032092184061388}, 'Vehicles': [{'position': (-126.7286477647468, 43.02887203185274), 'heading': -2.692517952027882}], 'Pedestrians': [], 'Objects': []}\n",
      "[['obj0_position', 'obj1_position'], ['obj0_heading', 'obj1_position'], ['obj1_heading']]\n",
      "objClassCountDict:  {'EgoCar': {'count': 1}, 'Vehicles': {'count': 1}}\n",
      "allObjCorrespondence:  [[0]]\n",
      "begin query\n",
      "queryLabel correspondence:  [0]\n",
      ".........................validating :  ['obj0_position', 'obj1_position'].......................\n",
      "validateLabelElement encoding done for validateLabelElement:  obj0_position\n",
      "NON-VALID ATTRIBUTES:  ['obj0_position', 'obj1_position']\n",
      "NOT VALID\n"
     ]
    }
   ],
   "source": [
    "import scenic\n",
    "scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/2_agent_scenario.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "unconditionAllAttributes(scenario)\n",
    "scenic_label, _ = scenario.generateForQuery(maxIterations=4000)\n",
    "label = convertScenicLabel(scenic_label)\n",
    "monolithic_translation = False\n",
    "outputDict = queryLabelSetup(scenario, label, ego_visibleDistance = 30, ego_viewAngle = 360, \\\n",
    "                  smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'],\\\n",
    "                    dataType = 'carla', monolithic_translation=monolithic_translation)\n",
    "print(\"label generated: \", len(scenic_label.objects))\n",
    "print(\"converted label: \", label)\n",
    "print(outputDict['sortedDependencyList'])\n",
    "errorBound = {}\n",
    "errorBound['x'] = 0.25 # meters == radius of the error margin ball around x\n",
    "errorBound['y'] = 0.25 # meters == radius of the error margin ball around x\n",
    "errorBound['heading'] = 0.0872 # radians = 5 degrees\n",
    "if not queryLabel(scenario, label, outputDict, errorBound, dataType='carla', debug=False, monolithic_translation=monolithic_translation):\n",
    "    print(\"NOT VALID\")\n",
    "else:\n",
    "    print(\"Valid \")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-9-8a0533fc8e5b>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-8a0533fc8e5b>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    'position': (36.12545501925976, 130.61377356935557), 'heading': -0.026739831827210958}\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'EgoCar': {'position': (195.0530128715603, 5.542774057505424), 'heading': -3.1250440581028167},x = scenario.original_objects[0].heading\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "3.114852821762582 - math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# # map_path = '/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town05.xodr'\n",
    "\n",
    "# for i in range(1):\n",
    "#     unconditionAllAttributes(scenario)\n",
    "#     sample = scenario.generateForQuery(maxIterations = 4000, verbosity=0)\n",
    "#     label, _ = sample\n",
    "#     if not validateLabel(scenario, label, dataType='nuScenes', debug=False):\n",
    "#         print(\"NOT VALID LABEL\")\n",
    "#         break\n",
    "#     else:\n",
    "#         print(\"label is valid: \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issue1: ahead/behind, left/right of uses the same heading angle as the referenced\n",
    "        (1) As a result, position & heading are jointly dependent\n",
    "        ==> what if we do not allow joint dependency between position and heading?\n",
    "        This assumes that we can decouple joint dependency between the two, if exists.\n",
    "        Is this true? Yes\n",
    "        ==> Limitation: if many there are many jointly dependent features all at once, it may not be feasible to solve\n",
    "        \n",
    "        (2) an obj can have its position be dependent on its heading because its heading is the same as the \n",
    "        heading of another object to which the obj is depedent\n",
    "        ==> is this only an issue with ego? because the ordering of the objects \n",
    "        ==> ==> solution: just keep the original objects ordering\n",
    "\n",
    "Issue2: my assumption that jointly dependent and dependent relationships are disjoint is wrong\n",
    "        (e.g. dependencyAnalysisTest4.scenic)\n",
    "        ==> it's not possible to capture such case since the attribute contains the intermediate variable\n",
    "        ==> another ordering process needs to be done within jointly dependent features based on dependence relations\n",
    "\n",
    "Issue3: Need to check the case when multiple attributes are dependent on another attributes\n",
    "        (e.g. )\n",
    "        \n",
    "\n",
    "Sorting Approach\n",
    "Since the objects are listed in the order the scenario is written, \n",
    "the order in which SMT translation is to be done stays intact\n",
    "The only issue now is to determine joint dependency\n",
    "==> before adding to joint dependency, check whether the jointly dependent attribute is dependent on any of the\n",
    "other jointly dependent attributes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
