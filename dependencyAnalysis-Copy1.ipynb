{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/core/errors.py:160: UserWarning: unable to install sys.excepthook to format Scenic backtraces\n",
      "  warnings.warn('unable to install sys.excepthook to format Scenic backtraces')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globalParameters.map:  /Users/edwardkim/Desktop/Scenic_Query/Scenic/examples/carla/ICCV_Scenic_Experiments/../../../tests/formats/opendrive/maps/CARLA/Town01.xodr\n",
      "globalParameters.map_options:  {}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scenic\n",
    "\n",
    "### NuScenes Query\n",
    "scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/parkedCar.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scenic\n",
    "### Dependency Analysis\n",
    "def cacheExprTreeNodes(attribute, nodeSet=None):\n",
    "    \"\"\"cache all the nodes of the input attribute's expression tree to the dictionary\"\"\"\n",
    "    if nodeSet is None:\n",
    "        nodeSet = set()\n",
    "    nodeSet.add(attribute)\n",
    "    if attribute._dependencies == ():\n",
    "        return nodeSet\n",
    "    for dep in attribute._dependencies:\n",
    "        cacheExprTreeNodes(dep, nodeSet)\n",
    "    return nodeSet\n",
    "\n",
    "def cacheAttributes(scenario, attributeList):\n",
    "    dictionary = {}\n",
    "    dictionary['objAttributes_names'] = []\n",
    "    dictionary['positionAttributes_names'] = []\n",
    "    dictionary['headingAttributes_names'] = []\n",
    "    \n",
    "    # cache all object attributes\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[i]\n",
    "        obj_name = 'obj'+str(i)\n",
    "        dictionary[obj_name] = {}\n",
    "        \n",
    "        for attribute in attributeList:\n",
    "            dictionary[obj_name][attribute] = {}\n",
    "            dictionary[obj_name][attribute]['self'] = getattr(obj, attribute)\n",
    "            dictionary[obj_name][attribute]['set'] = cacheExprTreeNodes(getattr(obj, attribute), None)\n",
    "            dictionary[obj_name][attribute]['intermediate_variables_set'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attributes_objs'] = set()\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attributes_objs'] = set()\n",
    "            dictionary['objAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'position':\n",
    "                dictionary['positionAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'heading':\n",
    "                dictionary['headingAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "                \n",
    "    return dictionary\n",
    "\n",
    "def checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "    \"\"\" checks whether the two attr1 and attr2 are jointly dependent on an intermediate variable\n",
    "    or is both dependent on another attribute. \n",
    "    Output:\n",
    "    True, if attr1 and attr2 are \"dependent\" on another attribute, not intermediate variable\n",
    "    False, attr1 and attr2 are both \"jointly dependent\" on an intermediate variable\n",
    "    \"\"\"\n",
    "    [obj1_name, attr1] = attr1_name.split('_')\n",
    "    attr1_obj = dictionary[obj1_name][attr1]['self']\n",
    "    attr1_jointly_dep_attr_names = dictionary[obj1_name][attr1]['jointly_dependent_attribute_names']\n",
    "    [obj2_name, attr2] = attr2_name.split('_')\n",
    "    attr2_obj = dictionary[obj2_name][attr2]['self']\n",
    "    attr2_jointly_dep_attr_names = dictionary[obj2_name][attr2]['jointly_dependent_attribute_names']\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr1_name: \", attr1_name)\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr2_name: \", attr2_name)\n",
    "    original_intersection = intersection\n",
    "    \n",
    "    objAttributes_names = dictionary['objAttributes_names'] \n",
    "    for attr_name in objAttributes_names:\n",
    "        if attr_name == attr1_name:\n",
    "            continue\n",
    "        elif attr_name == attr2_name:\n",
    "            break\n",
    "        else:\n",
    "            [obj_name, attr] = attr_name.split('_')\n",
    "            attr_obj = dictionary[obj_name][attr]['self']\n",
    "            attr_depSet = dictionary[obj_name][attr]['dependent_attribute_names']\n",
    "            \n",
    "            if attr_obj in original_intersection and attr_name not in attr1_jointly_dep_attr_names \\\n",
    "                and attr_name not in attr2_jointly_dep_attr_names: \n",
    "#                 print(\"other attr_name in the intersection: \", attr_name)\n",
    "                attr_cachedSet = dictionary[obj_name][attr]['set']\n",
    "                original_intersection = original_intersection - attr_cachedSet\n",
    "#                 print(\"len(original_intersection): \", len(original_intersection))\n",
    "                if len(original_intersection) == 0:\n",
    "#                     print(\"returns True\")\n",
    "                    # the intersection is another attribute\n",
    "                    return True\n",
    "    return False\n",
    "        \n",
    "def findAttribute(other_attr_obj, attr_dict, dictionary):\n",
    "    for obj_attr in attr_dict['dependent_attribute_names']:\n",
    "        [obj, attr] = obj_attr.split(\"_\")\n",
    "        if other_attr_obj is dictionary[obj][attr]['self']:\n",
    "            return obj_attr\n",
    "    return None\n",
    "\n",
    "def checkIntermediateSetMembership(attr_obj, attrIntermediateList):\n",
    "    for intermediateSet in attrIntermediateList:\n",
    "        if attr_obj in intermediateSet:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def analysis(objAttributes_names, dictionary):\n",
    "    for i in range(len(objAttributes_names)):\n",
    "        for j in range(len(objAttributes_names)):\n",
    "            if i < j:\n",
    "                attr1_name = objAttributes_names[i]\n",
    "                attr2_name = objAttributes_names[j]\n",
    "            \n",
    "                [obj_name1, attr1] = attr1_name.split('_')\n",
    "                [obj_name2, attr2] = attr2_name.split('_')\n",
    "        \n",
    "                attribute1 = dictionary[obj_name1][attr1]\n",
    "                attribute2 = dictionary[obj_name2][attr2]\n",
    "                attr1_obj = attribute1['self']\n",
    "                attr2_obj = attribute2['self']\n",
    "                \n",
    "                print(\"attr1_name: \", attr1_name)\n",
    "                print(\"attr2_name: \", attr2_name)\n",
    "                \n",
    "                if attr1_obj.isEquivalentTo(attr2_obj):\n",
    "                    continue\n",
    "                \n",
    "                set1 = attribute1['set']\n",
    "                set2 = attribute2['set']\n",
    "                intersection = set1.intersection(set2)\n",
    "                \n",
    "                if attr1_obj in intersection and attr1_obj not in attribute2['dependent_attributes_objs']:\n",
    "                    # attr2_obj is dependent on attr1_obj\n",
    "                    attribute2['dependent_attribute_names'].append(attr1_name)\n",
    "                    attribute2['dependent_attributes_objs'].add(attr1_obj)\n",
    "                elif attr2_obj in intersection and attr2_obj not in attribute1['dependent_attributes_objs']:\n",
    "                    # jointly_dependent case (e.g. depedendencyAnalysisTest4.scenic)\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "                        \n",
    "                elif len(intersection) > 0 \\\n",
    "                    and attr1_obj not in intersection and attr2_obj not in intersection \\\n",
    "                    and not checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "                    # the two attributes are jointly dependent (i.e. share intermediate variable(s))\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "                    \n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    return dictionary\n",
    "    \n",
    "def dependencyAnalysis(scenario, attributeList):\n",
    "    dictionary = cacheAttributes(scenario, attributeList)\n",
    "    dictionary['numberOfObjects'] = len(scenario.original_objects)\n",
    "    objAttributes_names = dictionary['objAttributes_names']\n",
    "    dictionary = analysis(objAttributes_names, dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def sortDependency(dictionary, scenario, monolithic_translation=False):\n",
    "    output = []\n",
    "    covered_attributes = []\n",
    "    \n",
    "    if not monolithic_translation:\n",
    "        for elem in dictionary['objAttributes_names']:\n",
    "            if elem in covered_attributes:\n",
    "                continue\n",
    "            covered_attributes.append(elem)\n",
    "            [obj_name, attr_name] = elem.split(\"_\")\n",
    "            joint_dep_set = dictionary[obj_name][attr_name]['jointly_dependent_attribute_names']\n",
    "            if len(joint_dep_set) > 0:\n",
    "                jointly_dependent_list = [elem]\n",
    "\n",
    "                for j in joint_dep_set:\n",
    "                    [j_obj_name, j_attr] = j.split(\"_\")\n",
    "                    if j not in covered_attributes:\n",
    "                        jointly_dependent_list.append(j)\n",
    "                        covered_attributes.append(j)\n",
    "                output.append(jointly_dependent_list)\n",
    "            else:\n",
    "                output.append([elem])\n",
    "    else:\n",
    "        output = [(dictionary['objAttributes_names'])]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "globalParameters.map:  /Users/edwardkim/Desktop/Scenic_Query/Scenic/examples/carla/ICCV_Scenic_Experiments/../../../tests/formats/opendrive/maps/CARLA/Town01.xodr\n",
      "globalParameters.map_options:  {}\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj0_heading\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj1_position\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj1_position\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj2_position\n",
      "attr2_name:  obj2_heading\n",
      "[['obj0_position'], ['obj0_heading'], ['obj1_position', 'obj1_heading', 'obj2_position', 'obj2_heading']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    }
   ],
   "source": [
    "## Test Dependency Analysis\n",
    "scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/parkedCar.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "\n",
    "attributeList = ['position', 'heading']\n",
    "d = dependencyAnalysis(scenario, attributeList)\n",
    "print(sortDependency(d, scenario))\n",
    "# obj0_heading = scenario.original_objects[0].heading\n",
    "# obj1_position = scenario.original_objects[1].position\n",
    "# print(type(obj0_heading))\n",
    "# print(type(obj1_position))\n",
    "# obj0_heading.isEquivalentTo(obj1_position)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SectorRegion>\n"
     ]
    }
   ],
   "source": [
    "x = scenario.original_objects[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.56\n"
     ]
    }
   ],
   "source": [
    "x = '23.56'\n",
    "def isFloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        print(\"not a float\")\n",
    "    return False\n",
    "print(isFloat(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "### SMT Translation Pipeline\n",
    "\n",
    "from scenic.core.regions import SectorRegion, CircularRegion\n",
    "from scenic.core.vectors import OrientedVector, Vector\n",
    "from scenic.core.distributions import *\n",
    "from scenic.domains.driving.roads import Network\n",
    "from scenic.core.regions import PointInRegionDistribution\n",
    "from scenic.core.type_support import TypecheckedDistribution\n",
    "from scenic.core.geometry import normalizeAngle\n",
    "import subprocess\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def resetConditionedVar(obj):\n",
    "    obj._conditioned = obj\n",
    "    if (obj._dependencies is None):\n",
    "        return None\n",
    "    for dep in obj._dependencies:\n",
    "        resetConditionedVar(dep)\n",
    "    return None\n",
    "\n",
    "def unconditionAllAttributes(scenario):\n",
    "    for obj in scenario.objects:\n",
    "        resetConditionedVar(obj.position)\n",
    "        resetConditionedVar(obj.heading)\n",
    "        \n",
    "def extractLabelAttribute(label, obj_index, attribute_name, objType, dataType, correspondence, egoObjIndex):\n",
    "    # Extract specific attribute from a label generated from a scenic program\n",
    "    \n",
    "#     print(\"extractLabelAttribute()\")\n",
    "#     print(\"label[objType]: \", label[objType])\n",
    "#     print(\"correspondence: \", correspondence)\n",
    "#     print(\"correspondence[obj_index]: \", correspondence[obj_index])\n",
    "#     print(\"attribute_name: \", attribute_name)\n",
    "#     print(\"obj_index: \", obj_index)\n",
    "#     print(\"egoObjIndex: \", egoObjIndex)\n",
    "    output = None\n",
    "    if obj_index != egoObjIndex:\n",
    "        if obj_index > egoObjIndex:\n",
    "            output = label[objType][correspondence[obj_index-1]][attribute_name]\n",
    "    else:\n",
    "        output = label['EgoCar'][attribute_name]\n",
    "\n",
    "    assert(output is not None)\n",
    "    if attribute_name == 'position':\n",
    "        return Vector(output[0], output[1])\n",
    "    if dataType == 'nuScenes':\n",
    "        output = normalizeAngle(math.radians(output-90)) #90 deg to reorient to Scenic's global coordinate system\n",
    "    return output\n",
    "        \n",
    "def initializeSMTFile(smt_file_path):\n",
    "    if os.path.isfile(smt_file_path):\n",
    "        os.remove(smt_file_path)\n",
    "    \n",
    "    open(smt_file_path, 'w').close()\n",
    "    writeSMTtoFile(smt_file_path, '(set-logic QF_NRA)')\n",
    "    \n",
    "def resetDictionary(cached_variables, smt_file_path):\n",
    "    regionAroundEgo = cached_variables['regionAroundEgo']\n",
    "    cached_variables.clear()\n",
    "    cached_variables['variables'] = []\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    \n",
    "def isFloat(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except ValueError:\n",
    "        return False\n",
    "    return False\n",
    "\n",
    "def translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                   dictionary, errorBound, debug=False):\n",
    "    \n",
    "    x_error_margin = str(errorBound['x'])\n",
    "    y_error_margin = str(errorBound['y'])\n",
    "    heading_error_margin = errorBound['heading']\n",
    "    \n",
    "    ## TODO: add error bound range to attributes\n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    obj_name, attr_type = attribute_name.split(\"_\")\n",
    "\n",
    "    # Encode the given attribute's expression tree\n",
    "    smt_var = attr_obj.encodeToSMT(smt_file_path, cached_variables, debug = debug)\n",
    "    if smt_var is None:\n",
    "        return False\n",
    "    \n",
    "    if attr_type == 'position':\n",
    "        assert(isinstance(attr_label, Vector))\n",
    "        x, y = smt_var\n",
    "        (x_label, y_label) = (str(attr_label.x), str(attr_label.y))\n",
    "        x_cond1 = smt_lessThanEq(smt_subtract(x_label, x_error_margin), x)\n",
    "        x_cond2 = smt_lessThanEq(x, smt_add(x_label, x_error_margin))\n",
    "        x_cond = smt_and(x_cond1, x_cond2)\n",
    "        \n",
    "        y_cond1 = smt_lessThanEq(smt_subtract(y_label, y_error_margin), y)\n",
    "        y_cond2 = smt_lessThanEq(y, smt_add(y_label, y_error_margin))\n",
    "        y_cond = smt_and(y_cond1, y_cond2)\n",
    "        \n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_and(x_cond, y_cond)))\n",
    "    else:\n",
    "        heading_label = str(attr_label)\n",
    "        \n",
    "        # normalize heading\n",
    "        norm_var = findVariableName(smt_file_path, cached_variables, 'normalized', debug=debug)\n",
    "        if not isinstance(isFloat(smt_var), float):\n",
    "            normalize1 = smt_assert(\"equal\", norm_var, smt_ite(smt_lessThanEq(\"3.1416\", smt_var), \\\n",
    "                                                        smt_subtract(smt_var,\"6.2832\"), \\\n",
    "                                                        smt_ite(smt_lessThanEq(smt_var, \"-3.1416\"), \\\n",
    "                                                        smt_add(smt_var,\"6.2832\"), smt_var)))\n",
    "            writeSMTtoFile(smt_file_path, normalize1)\n",
    "\n",
    "        else:\n",
    "            smt_var_float = isFloat(smt_var)\n",
    "            if 3.1416 < smt_var_float:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, str(smt_var_float-6.2832))\n",
    "            elif smt_var_float < -3.1416:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, str(6.2832-smt_var_float))\n",
    "            else:\n",
    "                normalize1 = smt_assert(\"equal\", norm_var, smt_var)\n",
    "            writeSMTtoFile(smt_file_path, normalize1)\n",
    "            \n",
    "        # check heading within [-pi, pi] interval\n",
    "        heading_cond1 = smt_lessThanEq(smt_subtract(heading_label, str(heading_error_margin)), norm_var)\n",
    "        heading_cond2 = smt_lessThanEq(norm_var, smt_add(heading_label, str(heading_error_margin)))\n",
    "        heading1 = smt_and(heading_cond1, heading_cond2)\n",
    "        \n",
    "        # check heading at wrap around case\n",
    "        if attr_label > 0:\n",
    "            smt_var2 = smt_add(smt_subtract(str(3.1416), str(heading_label)), smt_subtract(norm_var, str(-3.1416)))\n",
    "        else:\n",
    "            smt_var2 = smt_add(smt_subtract(str(heading_label), str(-3.1416)), smt_subtract(str(3.1416), norm_var))\n",
    "        heading_cond1 = smt_lessThanEq(str(-heading_error_margin), smt_var2)\n",
    "        heading_cond2 = smt_lessThanEq(smt_var2, str(heading_error_margin))\n",
    "        heading2 = smt_and(heading_cond1, heading_cond2)\n",
    "        \n",
    "        heading = smt_or(heading1, heading2)            \n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, heading))\n",
    "#         writeSMTtoFile(smt_file_path, smt_assert(None, smt_equal(str(attr_label), smt_var)))\n",
    "    return True\n",
    "        \n",
    "def findObjType(obj):\n",
    "    if \"Car\" in str(obj) or \"Truck\" in str(obj) or \"Motorcycle\" in str(obj) or \"Bicycle\" in str(obj):\n",
    "        return \"Vehicles\"\n",
    "    elif \"Pedestrian\" in str(obj):\n",
    "        return \"Pedestrians\"\n",
    "    elif \"Cone\" in str(obj) or \"Trash\" in str(obj):\n",
    "        return \"Objects\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return None\n",
    "\n",
    "def conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence, \\\n",
    "                        egoObjIndex, label):\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence, \\\n",
    "                                              egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "#         print(\"conditionAttributes attribute: \", attribute_name)\n",
    "#         print(\"conditionAttributes attr_label: \", attr_label)\n",
    "        if isinstance(attr_label, float) or isinstance(attr_label, int):\n",
    "            attr_obj.conditionTo(Constant(attr_label))\n",
    "        elif isinstance(attr_obj, PointInRegionDistribution):\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "            if isinstance(attr_obj.region, TypecheckedDistribution): \n",
    "                attr_obj.region.dist.conditionTo(attr_label)\n",
    "            else:\n",
    "                attr_obj.region.conditionTo(attr_label)\n",
    "        else:\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "\n",
    "def validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                         correspondence, egoObjIndex, dataType, errorBound, debug=False, falseTesting=False,\\\n",
    "                        monolithic_translation=False):\n",
    "    \n",
    "    count = 0\n",
    "    ## translate jointly dependent attribute expression trees\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence,\\\n",
    "                                          egoObjIndex)\n",
    "        print(\"validateLabelElement() attribute_name: \", attribute_name)\n",
    "        print(\"attr_label: \", attr_label)\n",
    "        print(\"correspondence: \", correspondence)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "        translated = translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                          dictionary, errorBound, debug)\n",
    "        if not translated:\n",
    "            print(\"TRANSLATION FAILED: NONE RETURNED\")\n",
    "            return False\n",
    "        print(\"validateLabelElement encoding done for validateLabelElement: \", attribute_name)\n",
    "#         if monolithic_translation:\n",
    "#             print(\"validLabelElement: Monolithic translation case -- condition attribute: \",attribute_name)\n",
    "#             conditionAttributes([attribute_name], dictionary, scenario, dataType, correspondence, \\\n",
    "#                         egoObjIndex, label)\n",
    "    \n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    writeSMTtoFile(smt_file_path, \"(check-sat)\")\n",
    "    writeSMTtoFile(smt_file_path, \"(exit)\")\n",
    "\n",
    "    if subprocess.call(\"./run_smt_encoding.sh\") == 1:\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def createCorrespondence(correspondence, objType, objTypeOrder, objTypeCorrespondence):\n",
    "    index = 0\n",
    "    correspond_copy = correspondence.copy()\n",
    "    for i in range(len(objTypeOrder)):\n",
    "        if objTypeOrder[i] == objType:\n",
    "            correspond_copy[i] = objTypeCorrespondence[index]\n",
    "            index += 1\n",
    "            if index == len(objTypeCorrespondence):\n",
    "                break\n",
    "    return correspond_copy\n",
    "    \n",
    "\n",
    "def findEgoObjIndex(scenario):\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        if scenario.original_objects[i] is scenario.egoObject:\n",
    "            return i\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refinePermutation(permutation_list, num_elem):\n",
    "    refined_list = set()\n",
    "    for perm in permutation_list:\n",
    "        refined_list.add(tuple(list(perm)[:num_elem]))\n",
    "    output = list(refined_list)\n",
    "    output.sort()\n",
    "    return output\n",
    "\n",
    "def generateObjectMatchingCorrespondenceSet(scenario, label):\n",
    "    objTypeOrder = []\n",
    "    objTypeDict = {}\n",
    "    \n",
    "    # Count the number of objType in the Scenic program and the label\n",
    "    for obj in scenario.original_objects:\n",
    "        if obj is not scenario.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objTypeOrder.append(objType)\n",
    "            \n",
    "            if objType not in objTypeDict.keys():\n",
    "                objTypeDict[objType] = {}\n",
    "                objTypeDict[objType]['label_count'] = len(label[objType])\n",
    "                objTypeDict[objType]['scenic_count'] = 1\n",
    "            else:\n",
    "                objTypeDict[objType]['scenic_count'] += 1\n",
    "    \n",
    "    print(\"objTypeOrder: \", objTypeOrder)\n",
    "    \n",
    "    # \n",
    "    total_permutation_number = 1\n",
    "    for objType in objTypeDict.keys():\n",
    "        label_count = objTypeDict[objType]['label_count']\n",
    "        scenic_count= objTypeDict[objType]['scenic_count']\n",
    "        assert(label_count >= scenic_count)\n",
    "        \n",
    "        index_list = [i for i in range(label_count)]\n",
    "        permutation_list = list(itertools.permutations(index_list))\n",
    "        objTypeDict[objType]['correspondence'] = refinePermutation(permutation_list, scenic_count)\n",
    "        total_permutation_number *= int(math.factorial(label_count) / math.factorial(label_count - scenic_count))\n",
    "    \n",
    "    print(\"total_permutation_number: \", total_permutation_number)\n",
    "    for objType in objTypeDict.keys():\n",
    "        print(\"objType: \", objType)\n",
    "        print(\"objType scenic_count: \", objTypeDict[objType]['scenic_count'])\n",
    "        print(\"objType label_count: \", objTypeDict[objType]['label_count'])\n",
    "        print(\"objType Correspondence: \", objTypeDict[objType]['correspondence'])\n",
    "        print(\"len(correspondence): \", len(objTypeDict[objType]['correspondence']))\n",
    "#     print(\"objTypeDict['Vehicles']['scenic_count']: \", objTypeDict['Vehicles']['scenic_count'])\n",
    "#     print(\"objTypeDict['Vehicles']['label_count']: \", objTypeDict['Vehicles']['label_count'])\n",
    "#     print(\"objTypeDict['Vehicles']['correspondence']: \", objTypeDict['Vehicles']['correspondence'])\n",
    "#     print(\"len(objTypeDict['Vehicles']['correspondence']): \", len(objTypeDict['Vehicles']['correspondence']))\n",
    "#     print(\"objTypeDict['Pedestrians']['scenic_count']\", objTypeDict['Pedestrians']['scenic_count'])\n",
    "#     print(\"objTypeDict['Pedestrians']['label_count']\", objTypeDict['Pedestrians']['label_count'])\n",
    "#     print(\"objTypeDict['Pedestrians']['correspondence']\", objTypeDict['Pedestrians']['correspondence'])\n",
    "#     print(\"objTypeDict['Objects']['count']\", objTypeDict['Objects']['count'])\n",
    "#     print(\"objTypeDict['Objects']['correspondence']\", objTypeDict['Objects']['correspondence'])\n",
    "    \n",
    "    # sort the types by the number of counts\n",
    "    types = list(objTypeDict.keys())\n",
    "    counts = [len(objTypeDict[objType]['correspondence']) for objType in types]\n",
    "    sorted_types = []\n",
    "    sorted_types_nums = []\n",
    "    \n",
    "    for i in range(len(types)):\n",
    "        elem = max(counts)\n",
    "        index = counts.index(max(counts))\n",
    "        sorted_types.append(types[index])\n",
    "        sorted_types_nums.append(elem)\n",
    "        del types[index]\n",
    "        del counts[index]\n",
    "    \n",
    "#     print(\"sorted_types: \", sorted_types)\n",
    "#     print(\"sorted_types_nums: \", sorted_types_nums)\n",
    "    \n",
    "    if len(objTypeOrder)==0:\n",
    "        return [(0,)]\n",
    "    \n",
    "    # compute the number of identical elements to insert per objType\n",
    "    num_identicals = []\n",
    "    for i in range(len(sorted_types)):\n",
    "        if i == len(sorted_types)-1:\n",
    "            num_identicals.append(1)\n",
    "        else:\n",
    "            num_identicals.append(np.prod(sorted_types_nums[i+1:]))\n",
    "    print(\"num_identicals: \", num_identicals)\n",
    "    \n",
    "    # create combinations of correspondences in the order of objTypeOrder\n",
    "    print(\"total_permutation_number: \", total_permutation_number)\n",
    "    correspondenceList = [[0]*len(objTypeOrder) for i in range(total_permutation_number)]\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "\n",
    "    # Handling first objType\n",
    "    objType = sorted_types[0]\n",
    "    for j in range(len(objTypeDict[objType]['correspondence'])):\n",
    "        correspondenceToEdit = correspondenceList[index]\n",
    "#         print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "        objTypeCorrespondence = objTypeDict[objType]['correspondence'][j]\n",
    "#         print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "        correspondence = createCorrespondence(correspondenceToEdit, objType, objTypeOrder, \\\n",
    "                                              objTypeCorrespondence)\n",
    "#         print(\"correspondence: \", correspondence)\n",
    "\n",
    "        for k in range(num_identicals[0]):\n",
    "            correspondenceList[index] = correspondence\n",
    "            index += 1\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "#     print(\"len(correspondenceList): \", len(correspondenceList))\n",
    "#     print(\"correspondenceList is Valid: \", len(correspondenceList)/num_identicals[0]==\\\n",
    "#           len(set([tuple(elem) for elem in correspondenceList])))\n",
    "    \n",
    "    # Handle the rest of objType \n",
    "    for i in range(1,len(sorted_types)):\n",
    "    # for each remaining object\n",
    "        index = 0\n",
    "        objType = sorted_types[i]\n",
    "#         print(\"processing objType: \", objType)\n",
    "        for j in range(len(objTypeDict[sorted_types[0]]['correspondence'])): \n",
    "        # loop for the number of first objType's correspondence\n",
    "            for k in range(len(objTypeDict[objType]['correspondence'])):\n",
    "            # loop for the number of distinct correspondences of remaining per obj\n",
    "                correspondenceToEdit = correspondenceList[index]\n",
    "#                 print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "                objTypeCorrespondence = objTypeDict[objType]['correspondence'][k]\n",
    "#                 print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "                correspondence = createCorrespondence(correspondenceToEdit, objType, \\\n",
    "                                objTypeOrder, objTypeCorrespondence)\n",
    "#                 print(\"correspondence: \", correspondence)\n",
    "                for l in range(num_identicals[i]):\n",
    "                    correspondenceList[index] = correspondence\n",
    "                    index += 1\n",
    "#                     print(\"index: \", index)\n",
    "                \n",
    "#                 print(\"kth loop completed: \", k)\n",
    "#             print(\"jth full loop completed: \", j)\n",
    "\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "    \n",
    "    return correspondenceList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/8_agent_scenario.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# x = generateObjectMatchingCorrespondenceSet(scenario)\n",
    "# print(\"finalOutput: \", x)\n",
    "# print(len(x))\n",
    "# print(len(set([tuple(elem) for elem in x])))\n",
    "\n",
    "# label = {}\n",
    "# label['Vehicles'] = [0,1,2]\n",
    "# label['Pedestrians'] = [0,1,2,3]\n",
    "# # scenic_script_path = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# # scenario = scenic.scenarioFromFile(scenic_script_path)\n",
    "# l = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "# print(len(l))\n",
    "# print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x = 'strin_0g'\n",
    "print('1' in x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Object Matching\n",
    "import math\n",
    "from scenic.domains.driving.roads import Network\n",
    "\n",
    "def conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    for obj_index in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[obj_index]\n",
    "        for attribute_name in attributeList:\n",
    "            objType = findObjType(obj)\n",
    "            attr_label = extractLabelAttribute(label, obj_index, attribute_name, objType, \\\n",
    "                                               dataType, correspondence, egoObjIndex)\n",
    "            if isinstance(attr_label, (float, int)):\n",
    "                attr_label = Constant(attr_label)\n",
    "            obj_attr = getattr(obj, attribute_name)\n",
    "            obj_attr.conditionTo(attr_label)\n",
    "\n",
    "def satisfyHardConstraints(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    unconditionAllAttributes(scenario)\n",
    "    conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType)\n",
    "    return scenario.checkRequirements()\n",
    "\n",
    "def scenarioObjClassCount(scenario):\n",
    "    # check whether the number of objects match per class\n",
    "    objClassCountDict = {}\n",
    "    for obj in scenario.original_objects:\n",
    "        objType = findObjType(obj)\n",
    "        if obj is not scenario.egoObject:\n",
    "            if objType not in objClassCountDict.keys():\n",
    "                objClassCountDict[objType] = {}\n",
    "                objClassCountDict[objType]['count'] = 1\n",
    "            else:\n",
    "                objClassCountDict[objType]['count'] += 1\n",
    "        else:\n",
    "            objClassCountDict['EgoCar'] = {}\n",
    "            objClassCountDict['EgoCar']['count'] = 1\n",
    "    return objClassCountDict\n",
    "\n",
    "def checkLabelValidity(label, objClassCountDict):\n",
    "    for objType in objClassCountDict.keys():\n",
    "        if objType == 'EgoCar':\n",
    "            continue\n",
    "        if len(label[objType]) < objClassCountDict[objType]['count']:\n",
    "            print(\"INVALID LABEL -- scenario vs label objects mismatch\")\n",
    "            print(\"Issue object type: \", objType)\n",
    "            print(\"len(label[objType]): \", len(label[objType]))\n",
    "            print(\"scenaro objectType's obj number: \", objClassCountDict[objType]['count'])\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def queryLabelSetup(scenario, smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'],\\\n",
    "                   dataType='carla', monolithic_translation=False):\n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # setup basic info\n",
    "    cached_variables = {}\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    network = Network.fromFile('/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town01.xodr', {})\n",
    "    egoObjIndex = findEgoObjIndex(scenario)\n",
    "    objClassCountDict = scenarioObjClassCount(scenario)\n",
    "    \n",
    "    # Sort Attribute Dependency \n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario, monolithic_translation)\n",
    "    \n",
    "    outputDict = {}\n",
    "    outputDict['cached_variables'] = cached_variables\n",
    "    outputDict['sortedDependencyList'] = sortedDependencyList\n",
    "    outputDict['egoObjIndex'] = egoObjIndex\n",
    "    outputDict['dictionary'] = dictionary\n",
    "    outputDict['objClassCountDict'] = objClassCountDict\n",
    "    outputDict['attributeList'] = attributeList\n",
    "    return outputDict\n",
    "\n",
    "def egoObjInList(jointlyDependentAttributeList, egoObjIndex):\n",
    "    for attr in jointlyDependentAttributeList:\n",
    "        if str(egoObjIndex) in attr:\n",
    "            return True\n",
    "    return False\n",
    "    \n",
    "def queryLabel(scenario, label, outputDict, errorBound, ego_visibleDistance = 30, ego_viewAngle = 135,\\\n",
    "               dataType='carla', smt_file_path='./test_smt_encoding.smt2', \\\n",
    "               debug=False, monolithic_translation = False, scenic_testing=False):\n",
    "    \n",
    "    objClassCountDict = outputDict['objClassCountDict']\n",
    "    print(\"objClassCountDict: \", objClassCountDict)\n",
    "    if not checkLabelValidity(label, objClassCountDict):\n",
    "        # number of objects do not match per class ==> reject the label\n",
    "        print(\"INVALD LABEL! Obj Count does not match\")\n",
    "        return False, False\n",
    "    \n",
    "    # Compute All Correspondence\n",
    "    allObjCorrespondence = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "    print(\"allObjCorrespondence: \", allObjCorrespondence)\n",
    "    \n",
    "    # Unpack variables\n",
    "    cached_variables = outputDict['cached_variables']\n",
    "    sortedDependencyList = outputDict['sortedDependencyList']\n",
    "    egoObjIndex = outputDict['egoObjIndex']\n",
    "    print(\"egoObjIndex: \", egoObjIndex)\n",
    "    dictionary = outputDict['dictionary']\n",
    "    attributeList = outputDict['attributeList']\n",
    "    \n",
    "    # Create Ego visible region\n",
    "    (ego_x, ego_y) = label['EgoCar']['position']\n",
    "    label_ego_pos = extractLabelAttribute(label, egoObjIndex, 'position', 'EgoCar', \\\n",
    "                                                  dataType, None, egoObjIndex)\n",
    "#     label_ego_heading = extractLabelAttribute(label, egoObjIndex, 'heading', 'EgoCar', \\\n",
    "#                                                   dataType, None, egoObjIndex)\n",
    "#     regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "#                                     math.radians(ego_viewAngle))\n",
    "    regionAroundEgo = CircularRegion(label_ego_pos, ego_visibleDistance)\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "#     print(\"begin query\")\n",
    "    for correspondence in allObjCorrespondence:\n",
    "        failed, egoInList = False, False\n",
    "        print(\"queryLabel correspondence: \", correspondence)\n",
    "        for jointlyDependentAttributeList in sortedDependencyList:\n",
    "            egoInList = egoObjInList(jointlyDependentAttributeList, egoObjIndex)\n",
    "            # Initialize smt file, if exists\n",
    "            initializeSMTFile(smt_file_path)\n",
    "            print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            if validateLabelElement(scenario, label, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                                            correspondence, egoObjIndex, dataType, errorBound, debug=debug, \\\n",
    "                                            monolithic_translation=monolithic_translation):\n",
    "                print(\".........................VALID ATTRIBUTE(S): \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "                conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, \\\n",
    "                                    correspondence, egoObjIndex, label)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "            else: # condition attributes in jointlyDependentAttributeList\n",
    "                print(\"INVALD LABEL -- NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "                failed = True\n",
    "                unconditionAllAttributes(scenario)\n",
    "                resetDictionary(cached_variables, smt_file_path)\n",
    "                if egoInList:\n",
    "                    print(\"ego object was in the list\")\n",
    "                    return True, False\n",
    "                break\n",
    "        \n",
    "        ## Check Hard Constraint Satisfaction\n",
    "        hardConstraintValid = satisfyHardConstraints(scenario, dictionary, label, attributeList, \\\n",
    "                                                 correspondence, egoObjIndex, dataType)\n",
    "        \n",
    "        if failed and scenic_testing:\n",
    "            return True, False\n",
    "        \n",
    "        if not failed and hardConstraintValid:\n",
    "            print(\"HARD CONSTRAINT SATISFIED\")\n",
    "            print(\"valid correspondence: \", correspondence)\n",
    "            return True, True\n",
    "        else:\n",
    "            if not failed and not hardConstraintValid:\n",
    "                print(\"INVALID LABELS -- HARD CONSTRAINT NOT SATISFIED\")\n",
    "            if scenic_testing:\n",
    "                # the first correspondence is valid\n",
    "                return True, False\n",
    "            failed = False\n",
    "            unconditionAllAttributes(scenario)\n",
    "            resetDictionary(cached_variables, smt_file_path)\n",
    "\n",
    "    return True, False\n",
    "\n",
    "def convertScenicLabel(scenic_label):\n",
    "    label = {}\n",
    "    label['EgoCar'] = {}\n",
    "    ego_pos = scenic_label.egoObject.position\n",
    "    label['EgoCar']['position'] = (ego_pos[0], ego_pos[1])\n",
    "    label['EgoCar']['heading'] = scenic_label.egoObject.heading\n",
    "    label['Vehicles'] = []\n",
    "    label['Pedestrians'] = []\n",
    "    label['Objects'] = []\n",
    "    for obj in scenic_label.objects:\n",
    "        if obj is not scenic_label.egoObject:\n",
    "            objType = findObjType(obj)\n",
    "            objDict = {}\n",
    "            objPos = obj.position\n",
    "            objDict['position'] = (objPos[0], objPos[1])\n",
    "            objDict['heading'] = obj.heading\n",
    "            label[objType].append(objDict)\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj0_heading\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj1_position\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj0_position\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj1_position\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj0_heading\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj1_heading\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj1_position\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj2_position\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj1_heading\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj2_position\n",
      "attr2_name:  obj2_heading\n",
      "attr1_name:  obj2_position\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj2_position\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj2_heading\n",
      "attr2_name:  obj3_position\n",
      "attr1_name:  obj2_heading\n",
      "attr2_name:  obj3_heading\n",
      "attr1_name:  obj3_position\n",
      "attr2_name:  obj3_heading\n",
      "sortedDependencyList:  [['obj0_position'], ['obj0_heading'], ['obj1_position'], ['obj1_heading'], ['obj2_position'], ['obj2_heading'], ['obj3_position'], ['obj3_heading']]\n",
      ".......... sampling a new scene from the scenic program ..........\n",
      "  Rejected sample 1 because of: object containment\n",
      "  Rejected sample 2 because of: object containment\n",
      "  Rejected sample 3 because of: object containment\n",
      "  Rejected sample 4 because of: object containment\n",
      "  Rejected sample 5 because of: object containment\n",
      "  Rejected sample 6 because of: object containment\n",
      "  Rejected sample 7 because of: object intersection\n",
      "  Rejected sample 8 because of: object intersection\n",
      "  Rejected sample 9 because of: object containment\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error: Lane with token  does not have a valid arcline path!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6ca52e8ec086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mscenic_script\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./examples/carla/ICCV_Human_Experiments/experiment4.scenic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0mscenario\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscenic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenarioFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenic_script\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mvalid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneratedScenicLabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_measurements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonolithic_translation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m# avg = sum(time_measurements)/len(time_measurements)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# print(avg)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6ca52e8ec086>\u001b[0m in \u001b[0;36mrunExperiment\u001b[0;34m(scenario, numTest, monolithic_translation)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0munconditionAllAttributes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenario\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".......... sampling a new scene from the scenic program ..........\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mscenic_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscenario\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerateForQuery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertScenicLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscenic_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mgeneratedScenicLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/scenarios.py\u001b[0m in \u001b[0;36mgenerateForQuery\u001b[0;34m(self, maxIterations, verbosity, feedback)\u001b[0m\n\u001b[1;32m    193\u001b[0m                                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternalSampler\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternalSampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeedback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                                 \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSamplable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m                         \u001b[0;32mexcept\u001b[0m \u001b[0mRejectionException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                                 \u001b[0mrejection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/distributions.py\u001b[0m in \u001b[0;36msampleAll\u001b[0;34m(quantities)\u001b[0m\n\u001b[1;32m    793\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquantities\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m                                 \u001b[0msubsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSamplable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/distributions.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, subsamples)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conditioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                                 \u001b[0msubsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conditioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleGiven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/distributions.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, subsamples)\u001b[0m\n\u001b[1;32m    803\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conditioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msubsamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 805\u001b[0;31m                                 \u001b[0msubsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conditioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleGiven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/distributions.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, subsamples)\u001b[0m\n\u001b[1;32m    805\u001b[0m                                 \u001b[0msubsamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conditioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampleGiven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubsamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msampleGiven\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/distributions.py\u001b[0m in \u001b[0;36msampleGiven\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1356\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m                 \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mevaluateInner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/core/vectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mdistributionMethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mvectorDistributionMethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Scenic_Query/Scenic/src/scenic/domains/driving/model.scenic\u001b[0m in \u001b[0;36mget_traffic_flow\u001b[0;34m(point)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_traffic_flow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mclosest_lane_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_closest_lane\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0marcline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_arcline_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosest_lane_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Set heading to dummy zero value (not needed for function below)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/scenic-35V3Qupd-py3.8/lib/python3.8/site-packages/nuscenes_devkit-1.1.1-py3.8.egg/nuscenes/map_expansion/map_api.py\u001b[0m in \u001b[0;36mget_arcline_path\u001b[0;34m(self, lane_token)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0marcline_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marcline_path_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlane_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0marcline_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Error: Lane with token {lane_token} does not have a valid arcline path!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marcline_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error: Lane with token  does not have a valid arcline path!"
     ]
    }
   ],
   "source": [
    "import scenic\n",
    "import time\n",
    "\n",
    "def runExperiment(scenario, numTest, monolithic_translation=False):\n",
    "    outputDict = queryLabelSetup(scenario,  smt_file_path='./test_smt_encoding.smt2', \\\n",
    "                                 attributeList = ['position', 'heading'],dataType = 'carla',\\\n",
    "                                 monolithic_translation=monolithic_translation)\n",
    "    errorBound = {}\n",
    "    errorBound['x'] = 0.25 # meters == radius of the error margin ball around x\n",
    "    errorBound['y'] = 0.25 # meters == radius of the error margin ball around y\n",
    "    errorBound['heading'] = 0.17453292 # radians = 10 degrees\n",
    "    print(\"sortedDependencyList: \", outputDict['sortedDependencyList'])\n",
    "    \n",
    "    generatedScenicLabels = []\n",
    "    time_measurements = []\n",
    "    \n",
    "    count = 0\n",
    "    for i in range(numTest):\n",
    "        count+=1 \n",
    "        unconditionAllAttributes(scenario)\n",
    "        print(\".......... sampling a new scene from the scenic program ..........\")\n",
    "        scenic_label, _ = scenario.generateForQuery(maxIterations=20000, verbosity=3)\n",
    "        label = convertScenicLabel(scenic_label)\n",
    "        generatedScenicLabels.append(label)\n",
    "#         label = {'EgoCar': {'position': (-2.9449264590890785, -314.61488173539584), 'heading': 3.1423412196072182}, 'Vehicles': [{'position': (-3.9936684742590733, -320.67343111267326), 'heading': 3.391950483052854}], 'Pedestrians': [], 'Objects': []}\n",
    "#         label = {'EgoCar': {'position': (97.55115659770372, -130.65978317673589), 'heading': 1.5351402745981155}, 'Vehicles': [], 'Pedestrians': [{'position': (90.4096787415988, -132.6216833589154), 'heading': -1.3026913094962842}], 'Objects': []}\n",
    "        print(\"sampled label: \", label)\n",
    "        current_time = time.time()\n",
    "        if not queryLabel(scenario, label, outputDict, errorBound, dataType='carla', debug=True, \\\n",
    "                          monolithic_translation=monolithic_translation, scenic_testing=True):\n",
    "            print(\"LABEL NOT VALID: \", label)\n",
    "            return False, generatedScenicLabels, time_measurements\n",
    "        else:\n",
    "            print(\"LABEL VALID : \", count)\n",
    "        query_runtime = time.time()-current_time\n",
    "        time_measurements.append(query_runtime)\n",
    "        print(\"query_runtime: \", query_runtime)\n",
    "        \n",
    "    return True, generatedScenicLabels, time_measurements\n",
    "\n",
    "scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment4.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "valid, generatedScenicLabels, time_measurements = runExperiment(scenario, numTest=1, monolithic_translation=False)\n",
    "# avg = sum(time_measurements)/len(time_measurements)\n",
    "# print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scenario.original_objects[2].position.object.object\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network.fromFile('/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town01.xodr', {})\n",
    "print(network.roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "def nuScenesExperiment(scenario, dataset_directory_path):\n",
    "    outputDict = queryLabelSetup(scenario,  smt_file_path='./test_smt_encoding.smt2', \\\n",
    "                                 attributeList = ['position', 'heading'],dataType = 'nuScenes')\n",
    "    errorBound = {}\n",
    "    errorBound['x'] = 0.25 # meters == radius of the error margin ball around x\n",
    "    errorBound['y'] = 0.25 # meters == radius of the error margin ball around y\n",
    "    errorBound['heading'] = 0.0872 # radians = 5 degrees\n",
    "    print(\"sortedDependencyList: \", outputDict['sortedDependencyList'])\n",
    "    \n",
    "    filenames = [file for file in os.listdir(dataset_directory_path) if file.endswith('.jpg')]\n",
    "    numFiles = len(filenames)\n",
    "    count = 0\n",
    "    valid_files = []\n",
    "    invalid_files = []\n",
    "    runtime_dict = {}\n",
    "    runtime_dict['runtime'] = []\n",
    "    runtime_dict['matched_runtime'] = []\n",
    "    \n",
    "    for file in filenames:\n",
    "        count+=1\n",
    "#         if count>1:\n",
    "#             break\n",
    "        print(\"# covered imgs: \", count)\n",
    "        img = mpimg.imread(os.path.join(dataset_directory_path, file))\n",
    "        plt.imshow(img)\n",
    "        plt.show()\n",
    "        unconditionAllAttributes(scenario)\n",
    "        label = nusc.get_img_data(file)\n",
    "        print(\"filename: \", file)\n",
    "        print(\"label: \", label)\n",
    "        current_time = time.time()\n",
    "        objCountMatched, valid = queryLabel(scenario, label, outputDict, errorBound, ego_visibleDistance = 50, \\\n",
    "                                              dataType='nuScenes', debug=False)\n",
    "        runtime = time.time()-current_time\n",
    "        if objCountMatched:\n",
    "            runtime_dict['matched_runtime'].append(runtime)\n",
    "        runtime_dict['runtime'].append(runtime)\n",
    "        \n",
    "        if not valid:\n",
    "            print(\"LABEL NOT VALID: \", file)\n",
    "            invalid_files.append(file)\n",
    "        else:\n",
    "            print(\"LABEL VALID: \", file)\n",
    "            valid_files.append(file)\n",
    "    return valid_files, invalid_files, runtime_dict\n",
    "\n",
    "directory = '/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data/experiment_results'\n",
    "subject1 = 'experiment_result_JayShenoy'\n",
    "subject2 = 'experiment_result_TaeSung'\n",
    "subject3 = 'experiment_result_Xiangyu'\n",
    "scenario_list = ['scenario1','scenario2','scenario3','scenario4','scenario5']\n",
    "dataset_directory_path = os.path.join(directory, 'data')\n",
    "scenic_script_path = \"./examples/carla/ICCV_Human_Experiments/experiment2.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script_path)\n",
    "valid_files, invalid_files, runtime_dict = nuScenesExperiment(scenario, dataset_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scenario1_errors = ['n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299229362404.jpg',\n",
    "          'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535729326412404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299149412404.jpg',\n",
    "          'n008-2018-08-30-15-52-26-0400__CAM_FRONT__1535659406262404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299240112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385159662404.jpg',\n",
    "          'n008-2018-09-18-15-26-58-0400__CAM_FRONT__1537299239112404.jpg',\n",
    "          'n008-2018-08-27-11-48-51-0400__CAM_FRONT__1535385153162404.jpg'\n",
    "         ]\n",
    "\n",
    "\n",
    "# dataset_directory_path = os.path.join(directory, 'scenario1_intersection')\n",
    "# filenames = set([file for file in os.listdir(dataset_directory_path) if file.endswith('.jpg')])\n",
    "# valids = set(valid_files)\n",
    "# diff_invalids = valids.difference(filenames)\n",
    "# print(len(diff_invalids))\n",
    "\n",
    "print(len(valid_files))\n",
    "print(len(invalid_files))\n",
    "print(\"avg runtime: \", sum(runtime_dict['runtime'])/len(runtime_dict['runtime']))\n",
    "print(\"avg matched runtime: \", sum(runtime_dict['matched_runtime'])/len(runtime_dict['matched_runtime']))\n",
    "# valids = valid_files.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenic_script_path = \"./examples/carla/ICCV_Human_Experiments/experiment4.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = scenario.original_objects[1].position\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scenicExperiment(numTest, monolithic_translation=False):\n",
    "    directory = \"./examples/carla/ICCV_Scenic_Experiments\"\n",
    "    timing_dict = {}\n",
    "    for i in range(1,11):\n",
    "        scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/\"+str(i)+\"_agent_scenario.scenic\"\n",
    "        scenario = scenic.scenarioFromFile(scenic_script)\n",
    "        valid, testedScenicLabels, time_measurements = runExperiment(scenario, numTest, monolithic_translation)\n",
    "        if not valid:\n",
    "            print(\"Invalid Experiment Detected, Stop experiment.....\")\n",
    "            return None\n",
    "        timing_dict[i] = {}\n",
    "        avg = sum(time_measurements)/len(time_measurements)\n",
    "        var = sum([(t-avg)**2 for t in time_measurements])/len(time_measurements)\n",
    "        timing_dict[i]['avg_runtime'] = avg\n",
    "        timing_dict[i]['runtime_variance'] = var\n",
    "        print(\"i: \", i)\n",
    "        print(\"avg: \", avg)\n",
    "        print(\"variance: \", var)\n",
    "        \n",
    "    return timing_dict\n",
    "\n",
    "timing_dict = scenicExperiment(numTest=1, monolithic_translation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import scenic\n",
    "# scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "# scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# # map_path = '/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town05.xodr'\n",
    "\n",
    "# for i in range(1):\n",
    "#     unconditionAllAttributes(scenario)\n",
    "#     sample = scenario.generateForQuery(maxIterations = 4000, verbosity=0)\n",
    "#     label, _ = sample\n",
    "#     if not validateLabel(scenario, label, dataType='nuScenes', debug=False):\n",
    "#         print(\"NOT VALID LABEL\")\n",
    "#         break\n",
    "#     else:\n",
    "#         print(\"label is valid: \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issue1: ahead/behind, left/right of uses the same heading angle as the referenced\n",
    "        (1) As a result, position & heading are jointly dependent\n",
    "        ==> what if we do not allow joint dependency between position and heading?\n",
    "        This assumes that we can decouple joint dependency between the two, if exists.\n",
    "        Is this true? Yes\n",
    "        ==> Limitation: if many there are many jointly dependent features all at once, it may not be feasible to solve\n",
    "        \n",
    "        (2) an obj can have its position be dependent on its heading because its heading is the same as the \n",
    "        heading of another object to which the obj is depedent\n",
    "        ==> is this only an issue with ego? because the ordering of the objects \n",
    "        ==> ==> solution: just keep the original objects ordering\n",
    "\n",
    "Issue2: my assumption that jointly dependent and dependent relationships are disjoint is wrong\n",
    "        (e.g. dependencyAnalysisTest4.scenic)\n",
    "        ==> it's not possible to capture such case since the attribute contains the intermediate variable\n",
    "        ==> another ordering process needs to be done within jointly dependent features based on dependence relations\n",
    "\n",
    "Issue3: Need to check the case when multiple attributes are dependent on another attributes\n",
    "        (e.g. )\n",
    "        \n",
    "\n",
    "Sorting Approach\n",
    "Since the objects are listed in the order the scenario is written, \n",
    "the order in which SMT translation is to be done stays intact\n",
    "The only issue now is to determine joint dependency\n",
    "==> before adding to joint dependency, check whether the jointly dependent attribute is dependent on any of the\n",
    "other jointly dependent attributes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
