{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scenic\n",
    "\n",
    "### NuScenes Query\n",
    "from scenic.simulators.carla.nusc_query_api import NuscQueryAPI\n",
    "nusc = NuscQueryAPI(version='v1.0-trainval', \\\n",
    "                    dataroot='/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependency Analysis\n",
    "def cacheExprTreeNodes(attribute, nodeSet=None):\n",
    "    \"\"\"cache all the nodes of the input attribute's expression tree to the dictionary\"\"\"\n",
    "    if nodeSet is None:\n",
    "        nodeSet = set()\n",
    "    nodeSet.add(attribute)\n",
    "    if attribute._dependencies == ():\n",
    "        return nodeSet\n",
    "    for dep in attribute._dependencies:\n",
    "        cacheExprTreeNodes(dep, nodeSet)\n",
    "    return nodeSet\n",
    "\n",
    "def cacheAttributes(scenario, attributeList):\n",
    "    dictionary = {}\n",
    "    dictionary['objAttributes_names'] = []\n",
    "    dictionary['positionAttributes_names'] = []\n",
    "    dictionary['headingAttributes_names'] = []\n",
    "    \n",
    "    # cache all object attributes\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[i]\n",
    "        obj_name = 'obj'+str(i)\n",
    "        dictionary[obj_name] = {}\n",
    "        \n",
    "        for attribute in attributeList:\n",
    "            dictionary[obj_name][attribute] = {}\n",
    "            dictionary[obj_name][attribute]['self'] = getattr(obj, attribute)\n",
    "            dictionary[obj_name][attribute]['set'] = cacheExprTreeNodes(getattr(obj, attribute), None)\n",
    "            dictionary[obj_name][attribute]['intermediate_variables_set'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attribute_names'] = []\n",
    "            dictionary[obj_name][attribute]['dependent_attributes_objs'] = set()\n",
    "            dictionary[obj_name][attribute]['jointly_dependent_attributes_objs'] = set()\n",
    "            dictionary['objAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'position':\n",
    "                dictionary['positionAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "            if attribute == 'heading':\n",
    "                dictionary['headingAttributes_names'].append(obj_name+\"_\"+attribute)\n",
    "                \n",
    "    return dictionary\n",
    "\n",
    "def checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "    \"\"\" checks whether the two attr1 and attr2 are jointly dependent on an intermediate variable\n",
    "    or is both dependent on another attribute. \n",
    "    Output:\n",
    "    True, if attr1 and attr2 are \"dependent\" on another attribute, not intermediate variable\n",
    "    False, attr1 and attr2 are both \"jointly dependent\" on an intermediate variable\n",
    "    \"\"\"\n",
    "    [obj1_name, attr1] = attr1_name.split('_')\n",
    "    attr1_obj = dictionary[obj1_name][attr1]['self']\n",
    "    attr1_jointly_dep_attr_names = dictionary[obj1_name][attr1]['jointly_dependent_attribute_names']\n",
    "    [obj2_name, attr2] = attr2_name.split('_')\n",
    "    attr2_obj = dictionary[obj2_name][attr2]['self']\n",
    "    attr2_jointly_dep_attr_names = dictionary[obj2_name][attr2]['jointly_dependent_attribute_names']\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr1_name: \", attr1_name)\n",
    "#     print(\"checkDependenceOnAnotherAttribute attr2_name: \", attr2_name)\n",
    "    original_intersection = intersection\n",
    "    \n",
    "    objAttributes_names = dictionary['objAttributes_names'] \n",
    "    for attr_name in objAttributes_names:\n",
    "        if attr_name == attr1_name:\n",
    "            continue\n",
    "        elif attr_name == attr2_name:\n",
    "            break\n",
    "        else:\n",
    "            [obj_name, attr] = attr_name.split('_')\n",
    "            attr_obj = dictionary[obj_name][attr]['self']\n",
    "            attr_depSet = dictionary[obj_name][attr]['dependent_attribute_names']\n",
    "            \n",
    "            if attr_obj in original_intersection and attr_name not in attr1_jointly_dep_attr_names \\\n",
    "                and attr_name not in attr2_jointly_dep_attr_names: \n",
    "#                 print(\"other attr_name in the intersection: \", attr_name)\n",
    "                attr_cachedSet = dictionary[obj_name][attr]['set']\n",
    "                original_intersection = original_intersection - attr_cachedSet\n",
    "#                 print(\"len(original_intersection): \", len(original_intersection))\n",
    "                if len(original_intersection) == 0:\n",
    "#                     print(\"returns True\")\n",
    "                    # the intersection is another attribute\n",
    "                    return True\n",
    "    return False\n",
    "        \n",
    "def findAttribute(other_attr_obj, attr_dict, dictionary):\n",
    "    for obj_attr in attr_dict['dependent_attribute_names']:\n",
    "        [obj, attr] = obj_attr.split(\"_\")\n",
    "        if other_attr_obj is dictionary[obj][attr]['self']:\n",
    "            return obj_attr\n",
    "    return None\n",
    "\n",
    "def checkIntermediateSetMembership(attr_obj, attrIntermediateList):\n",
    "    for intermediateSet in attrIntermediateList:\n",
    "        if attr_obj in intermediateSet:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def analysis(objAttributes_names, dictionary):\n",
    "    for i in range(len(objAttributes_names)):\n",
    "        for j in range(len(objAttributes_names)):\n",
    "            if i < j:\n",
    "                attr1_name = objAttributes_names[i]\n",
    "                attr2_name = objAttributes_names[j]\n",
    "                [obj_name1, attr1] = attr1_name.split('_')\n",
    "                [obj_name2, attr2] = attr2_name.split('_')\n",
    "        \n",
    "                attribute1 = dictionary[obj_name1][attr1]\n",
    "                attribute2 = dictionary[obj_name2][attr2]\n",
    "                attr1_obj = attribute1['self']\n",
    "                attr2_obj = attribute2['self']\n",
    "                \n",
    "                set1 = attribute1['set']\n",
    "                set2 = attribute2['set']\n",
    "                intersection = set1.intersection(set2)\n",
    "                \n",
    "                if attr1_obj in intersection and attr1_obj not in attribute2['dependent_attributes_objs']:\n",
    "                    # attr2_obj is dependent on attr1_obj\n",
    "                    attribute2['dependent_attribute_names'].append(attr1_name)\n",
    "                    attribute2['dependent_attributes_objs'].add(attr1_obj)\n",
    "                elif attr2_obj in intersection and attr2_obj not in attribute1['dependent_attributes_objs']:\n",
    "                    # jointly_dependent case (e.g. depedendencyAnalysisTest4.scenic)\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "                        \n",
    "                elif len(intersection) > 0 \\\n",
    "                    and attr1_obj not in intersection and attr2_obj not in intersection \\\n",
    "                    and not checkDependenceOnAnotherAttribute(intersection, attr1_name, attr2_name, dictionary):\n",
    "                    # the two attributes are jointly dependent (i.e. share intermediate variable(s))\n",
    "                    if attr2_name not in attribute1['jointly_dependent_attribute_names']:\n",
    "                        attribute1['jointly_dependent_attribute_names'].append(attr2_name)\n",
    "                        attribute1['jointly_dependent_attributes_objs'].add(attr2_obj)     \n",
    "                        attribute1['intermediate_variables_set'].append(intersection)\n",
    "                    \n",
    "                    if attr1_name not in attribute2['jointly_dependent_attribute_names']:\n",
    "                        attribute2['jointly_dependent_attribute_names'].append(attr1_name)\n",
    "                        attribute2['jointly_dependent_attributes_objs'].add(attr1_obj)\n",
    "                        attribute2['intermediate_variables_set'].append(intersection)\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "    return dictionary\n",
    "    \n",
    "def dependencyAnalysis(scenario, attributeList):\n",
    "    dictionary = cacheAttributes(scenario, attributeList)\n",
    "    dictionary['numberOfObjects'] = len(scenario.original_objects)\n",
    "    objAttributes_names = dictionary['objAttributes_names']\n",
    "    dictionary = analysis(objAttributes_names, dictionary)\n",
    "    return dictionary\n",
    "\n",
    "def sortDependency(dictionary, scenario):\n",
    "    output = []\n",
    "    covered_attributes = []\n",
    "    \n",
    "    for elem in dictionary['objAttributes_names']:\n",
    "        if elem in covered_attributes:\n",
    "            continue\n",
    "        covered_attributes.append(elem)\n",
    "        [obj_name, attr_name] = elem.split(\"_\")\n",
    "        joint_dep_set = dictionary[obj_name][attr_name]['jointly_dependent_attribute_names']\n",
    "        if len(joint_dep_set) > 0:\n",
    "            jointly_dependent_list = [elem]\n",
    "            \n",
    "            for j in joint_dep_set:\n",
    "                [j_obj_name, j_attr] = j.split(\"_\")\n",
    "                jointly_dependent_list.append(j)\n",
    "                covered_attributes.append(j)\n",
    "            output.append(jointly_dependent_list)\n",
    "        else:\n",
    "            output.append([elem])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Test Dependency Analysis\n",
    "\n",
    "# attributeList = ['position', 'heading']\n",
    "# d = dependencyAnalysis(scenario, attributeList)\n",
    "# print(sortDependency(d, scenario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SMT Translation Pipeline\n",
    "\n",
    "from scenic.core.regions import SectorRegion\n",
    "from scenic.core.vectors import OrientedVector, Vector\n",
    "from scenic.core.distributions import *\n",
    "from scenic.domains.driving.roads import Network\n",
    "from scenic.core.regions import PointInRegionDistribution\n",
    "from scenic.core.type_support import TypecheckedDistribution\n",
    "import subprocess\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "def resetConditionedVar(obj):\n",
    "    obj._conditioned = obj\n",
    "    if (obj._dependencies is None):\n",
    "        return None\n",
    "    for dep in obj._dependencies:\n",
    "        resetConditionedVar(dep)\n",
    "    return None\n",
    "\n",
    "def unconditionAllAttributes(scenario):\n",
    "    for obj in scenario.objects:\n",
    "        resetConditionedVar(obj.position)\n",
    "        resetConditionedVar(obj.heading)\n",
    "        \n",
    "def extractLabelAttribute(label, obj_index, attribute_name, objType, dataType, correspondence, egoObjIndex):\n",
    "    # Extract specific attribute from a label generated from a scenic program\n",
    "    if dataType == 'carla':\n",
    "        return getattr(label.objects[obj_index], attribute_name)\n",
    "    elif dataType == 'nuScenes':\n",
    "        if obj_index != egoObjIndex:\n",
    "            if obj_index > egoObjIndex:\n",
    "                obj_index -= 1\n",
    "            output = label[objType][correspondence[obj_index]][attribute_name]\n",
    "            if attribute_name == 'position':\n",
    "                return Vector(output[0], output[1])\n",
    "            return output\n",
    "        else:\n",
    "            output = label['EgoCar'][attribute_name]\n",
    "            if attribute_name == 'position':\n",
    "                return Vector(output[0], output[1])\n",
    "            return output\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "        \n",
    "def initializeSMTFile(smt_file_path):\n",
    "    if os.path.isfile(smt_file_path):\n",
    "        os.remove(smt_file_path)\n",
    "    \n",
    "    open(smt_file_path, 'w').close()\n",
    "    writeSMTtoFile(smt_file_path, '(set-logic QF_NRA)')\n",
    "    \n",
    "def resetDictionary(cached_variables, regionAroundEgo, smt_file_path):\n",
    "    cached_variables.clear()\n",
    "    cached_variables['variables'] = []\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "\n",
    "def translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                   dictionary, debug=False):\n",
    "    \n",
    "    ## TODO: add error bound range to attributes\n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    obj_name, attr_type = attribute_name.split(\"_\")\n",
    "\n",
    "    # Encode the given attribute's expression tree\n",
    "    smt_var = attr_obj.encodeToSMT(smt_file_path, cached_variables, debug = debug)\n",
    "    \n",
    "    if attr_type == 'position':\n",
    "        assert(isinstance(attr_label, Vector))\n",
    "        (x_label, y_label) = (str(attr_label.x), str(attr_label.y))\n",
    "        (x_cond, y_cond) = vector_operation_smt((x_label, y_label), \"equal\", smt_var)\n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_and(x_cond, y_cond)))\n",
    "    else:\n",
    "        writeSMTtoFile(smt_file_path, smt_assert(None, smt_equal(str(attr_label), smt_var)))\n",
    "        \n",
    "def findObjType(obj):\n",
    "    if \"Car\" in str(obj) or \"Truck\" in str(obj) or \"Motorcycle\" in str(obj) or \"Bicycle\" in str(obj):\n",
    "        return \"Vehicles\"\n",
    "    elif \"Pedestrian\" in str(obj):\n",
    "        return \"Pedestrians\"\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    return None\n",
    "\n",
    "def conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence, \\\n",
    "                        egoObjIndex, label):\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence, \\\n",
    "                                              egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "#         print(\"conditionAttributes attribute: \", attribute_name)\n",
    "        if isinstance(attr_label, float) or isinstance(attr_label, int):\n",
    "            attr_obj.conditionTo(Constant(attr_label))\n",
    "        elif isinstance(attr_obj, PointInRegionDistribution):\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "            if isinstance(attr_obj.region, TypecheckedDistribution): \n",
    "                attr_obj.region.dist.conditionTo(attr_label)\n",
    "            else:\n",
    "                attr_obj.region.conditionTo(attr_label)\n",
    "        else:\n",
    "            attr_obj.conditionTo(attr_label)\n",
    "\n",
    "def validateLabelElement(scenario, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                         correspondence, egoObjIndex, dataType, debug=False, falseTesting=False):\n",
    "    \n",
    "    ## translate jointly dependent attribute expression trees\n",
    "    for attribute_name in jointlyDependentAttributeList:\n",
    "        obj_name, attr_name = attribute_name.split(\"_\")\n",
    "        obj_index = int(obj_name.split(\"obj\")[1])\n",
    "        objType = findObjType(scenario.original_objects[obj_index])\n",
    "        attr_label = extractLabelAttribute(label, obj_index, attr_name, objType, dataType, correspondence,\\\n",
    "                                          egoObjIndex)\n",
    "        attr_obj = dictionary[obj_name][attr_name]['self']\n",
    "\n",
    "        translateAttributeExpressionTree(attribute_name, attr_obj, attr_label, cached_variables, \\\n",
    "                                          dictionary, debug)\n",
    "    \n",
    "    smt_file_path = cached_variables['smt_file_path']\n",
    "    writeSMTtoFile(smt_file_path, \"(check-sat)\")\n",
    "    writeSMTtoFile(smt_file_path, \"(exit)\")\n",
    "\n",
    "    if subprocess.call(\"./run_smt_encoding.sh\") == 1:\n",
    "        ## This means that jointly dependent attributes are all valid\n",
    "        ## so condition attributes \n",
    "#         conditionAttributes(jointlyDependentAttributeList, dictionary)\n",
    "        return True\n",
    "        \n",
    "    return False\n",
    "\n",
    "def generateObjectMatchingCorrespondenceSet(scenario, label):\n",
    "    objTypeOrder = []\n",
    "    objTypeDict = {}\n",
    "    \n",
    "    for obj in scenario.original_objects:\n",
    "        objType = findObjType(obj)\n",
    "        objTypeOrder.append(objType)\n",
    "        if objType not in objTypeDict.keys():\n",
    "            objTypeDict[objType] = {}\n",
    "            objTypeDict[objType]['count'] = 1\n",
    "        else:\n",
    "            objTypeDict[objType]['count'] += 1\n",
    "    print(\"objTypeOrder: \", objTypeOrder)\n",
    "    \n",
    "    total_permutation_number = 1\n",
    "    for objType in objTypeDict.keys():\n",
    "        count = objTypeDict[objType]['count']\n",
    "        index_list = [i for i in range(count)]\n",
    "        objTypeDict[objType]['correspondence'] = list(itertools.permutations(index_list))\n",
    "        total_permutation_number *= len(objTypeDict[objType]['correspondence'])\n",
    "    \n",
    "    print(\"total_permutation_number: \", total_permutation_number)\n",
    "    print(\"objTypeDict['Vehicles']['count']: \", objTypeDict['Vehicles']['count'])\n",
    "    print(\"objTypeDict['Vehicles']['correspondence']: \", objTypeDict['Vehicles']['correspondence'])\n",
    "    print(\"len(objTypeDict['Vehicles']['correspondence']): \", len(objTypeDict['Vehicles']['correspondence']))\n",
    "    print(\"objTypeDict['Pedestrians']['count']\", objTypeDict['Pedestrians']['count'])\n",
    "    print(\"objTypeDict['Pedestrians']['correspondence']\", objTypeDict['Pedestrians']['correspondence'])\n",
    "    \n",
    "    # sort the types by the number of counts\n",
    "    types = list(objTypeDict.keys())\n",
    "    counts = [objTypeDict[objType]['count'] for objType in types]\n",
    "    sorted_types = []\n",
    "    sorted_types_nums = []\n",
    "    for i in range(len(types)):\n",
    "        elem = max(counts)\n",
    "        index = counts.index(max(counts))\n",
    "        sorted_types.append(types[index])\n",
    "        sorted_types_nums.append(elem)\n",
    "        del types[index]\n",
    "        del counts[index]\n",
    "    \n",
    "    print(\"sorted_types: \", sorted_types)\n",
    "    print(\"sorted_types_nums: \", sorted_types_nums)\n",
    "    \n",
    "    # compute the number of identical elements to insert per objType\n",
    "    num_identicals = []\n",
    "    for i in range(len(sorted_types)):\n",
    "        if i == len(sorted_types)-1:\n",
    "            num_identicals.append(1)\n",
    "        else:\n",
    "            num_identicals.append(np.prod(sorted_types_nums[i+1:]))\n",
    "    print(\"num_identicals: \", num_identicals)\n",
    "    \n",
    "    # create combinations of correspondences in the order of objTypeOrder\n",
    "    correspondenceList = [[0]*len(objTypeOrder) for i in range(total_permutation_number)]\n",
    "#     print(\"correspondenceList: \", correspondenceList)\n",
    "    for i in range(len(sorted_types)-1):\n",
    "        objType = sorted_types[i]\n",
    "        index = 0\n",
    "#         print(\"objType: \", objType)\n",
    "        \n",
    "        for j in range(len(objTypeDict[objType]['correspondence'])):\n",
    "            correspondenceToEdit = correspondenceList[index]\n",
    "#             print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "            objTypeCorrespondence = objTypeDict[objType]['correspondence'][j]\n",
    "#             print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "            correspondence = createCorrespondence(correspondenceToEdit, objType, objTypeOrder, objTypeCorrespondence)\n",
    "#             print(\"correspondence: \", correspondence)\n",
    "            \n",
    "            for k in range(num_identicals[i]):\n",
    "                correspondenceList[index] = correspondence\n",
    "                index += 1\n",
    "                \n",
    "    num_lastObjType_correspondence = len(objTypeDict[sorted_types[-1]]['correspondence'])\n",
    "    print(\"num_lastObjType_correspondence: \", num_lastObjType_correspondence)\n",
    "    num_iteration = int(total_permutation_number / num_lastObjType_correspondence)\n",
    "    print(\"num_iteration: \", num_iteration)\n",
    "    assert(total_permutation_number == num_iteration * num_lastObjType_correspondence)\n",
    "    lastObjType = sorted_types[-1]\n",
    "    print(\"lastObjType: \", lastObjType)\n",
    "    index = 0\n",
    "    finalCorrespondenceList = []\n",
    "    for m in range(num_iteration):\n",
    "        for n in range(num_lastObjType_correspondence):\n",
    "#             print(\"index: \", index)\n",
    "            correspondenceToEdit = correspondenceList[index]\n",
    "#             print(\"correspondenceToEdit: \", correspondenceToEdit)\n",
    "            objTypeCorrespondence = objTypeDict[lastObjType]['correspondence'][n]\n",
    "#             print(\"objTypeCorrespondence: \", objTypeCorrespondence)\n",
    "            correspondence = createCorrespondence(correspondenceToEdit, lastObjType, objTypeOrder, objTypeCorrespondence)\n",
    "#             print(\"correspondence: \", correspondence)\n",
    "            finalCorrespondenceList.append(tuple(correspondence))\n",
    "            index += 1\n",
    "\n",
    "    return finalCorrespondenceList\n",
    "\n",
    "def createCorrespondence(correspondence, objType, objTypeOrder, objTypeCorrespondence):\n",
    "    index = 0\n",
    "    for i in range(len(objTypeOrder)):\n",
    "        if objTypeOrder[i] == objType:\n",
    "            correspondence[i] = objTypeCorrespondence[index]\n",
    "            index += 1\n",
    "            if index == len(objTypeCorrespondence):\n",
    "                break\n",
    "    return correspondence\n",
    "    \n",
    "\n",
    "def findEgoObjIndex(scenario):\n",
    "    for i in range(len(scenario.original_objects)):\n",
    "        if scenario.original_objects[i] is scenario.egoObject:\n",
    "            return i\n",
    "    return None\n",
    "\n",
    "def validateLabel(scenario, label, map_path, map_source='carla', ego_visibleDistance = 50, ego_viewAngle = 360, \\\n",
    "                  smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'], \\\n",
    "                  debug = False):\n",
    "    #TODO: need to add object matching\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # Initialize smt file, if exists\n",
    "    initializeSMTFile(smt_file_path)\n",
    "    \n",
    "    # Create Ego's VisibleRegion\n",
    "    cached_variables = {}\n",
    "#     if map_source == 'carla':\n",
    "#         cached_variables['network'] = Network.fromFile(map_path, None)\n",
    "#     elif map_source == 'nuScenes':\n",
    "#         raise NotImplementedError\n",
    "#     else:\n",
    "#          raise NotImplementedError\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    label_ego_pos = label.egoObject.position\n",
    "    label_ego_heading = label.egoObject.heading\n",
    "    regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "                                    math.radians(ego_viewAngle))\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario)\n",
    "    print(\"sortedDependencyList: \", sortedDependencyList)\n",
    "    \n",
    "    for jointlyDependentAttributeList in sortedDependencyList:\n",
    "        print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "        if not validateLabelElement(scenario, cached_variables, jointlyDependentAttributeList, dictionary, debug):\n",
    "            print(\"NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "            return False\n",
    "        else: # condition attributes in jointlyDependentAttributeList\n",
    "            print(\".........................valid attribute: \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, correspondence,\\\n",
    "                                   label)\n",
    "            resetDictionary(cached_variables, regionAroundEgo, smt_file_path)\n",
    "    \n",
    "    ## Check Hard Constraint Satisfaction\n",
    "    if not scenario.checkRequirements():\n",
    "        return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objTypeOrder:  ['Vehicles', 'Vehicles', 'Pedestrians', 'Vehicles', 'Vehicles', 'Pedestrians', 'Vehicles']\n",
      "total_permutation_number:  240\n",
      "objTypeDict['Vehicles']['count']:  5\n",
      "objTypeDict['Vehicles']['correspondence']:  [(0, 1, 2, 3, 4), (0, 1, 2, 4, 3), (0, 1, 3, 2, 4), (0, 1, 3, 4, 2), (0, 1, 4, 2, 3), (0, 1, 4, 3, 2), (0, 2, 1, 3, 4), (0, 2, 1, 4, 3), (0, 2, 3, 1, 4), (0, 2, 3, 4, 1), (0, 2, 4, 1, 3), (0, 2, 4, 3, 1), (0, 3, 1, 2, 4), (0, 3, 1, 4, 2), (0, 3, 2, 1, 4), (0, 3, 2, 4, 1), (0, 3, 4, 1, 2), (0, 3, 4, 2, 1), (0, 4, 1, 2, 3), (0, 4, 1, 3, 2), (0, 4, 2, 1, 3), (0, 4, 2, 3, 1), (0, 4, 3, 1, 2), (0, 4, 3, 2, 1), (1, 0, 2, 3, 4), (1, 0, 2, 4, 3), (1, 0, 3, 2, 4), (1, 0, 3, 4, 2), (1, 0, 4, 2, 3), (1, 0, 4, 3, 2), (1, 2, 0, 3, 4), (1, 2, 0, 4, 3), (1, 2, 3, 0, 4), (1, 2, 3, 4, 0), (1, 2, 4, 0, 3), (1, 2, 4, 3, 0), (1, 3, 0, 2, 4), (1, 3, 0, 4, 2), (1, 3, 2, 0, 4), (1, 3, 2, 4, 0), (1, 3, 4, 0, 2), (1, 3, 4, 2, 0), (1, 4, 0, 2, 3), (1, 4, 0, 3, 2), (1, 4, 2, 0, 3), (1, 4, 2, 3, 0), (1, 4, 3, 0, 2), (1, 4, 3, 2, 0), (2, 0, 1, 3, 4), (2, 0, 1, 4, 3), (2, 0, 3, 1, 4), (2, 0, 3, 4, 1), (2, 0, 4, 1, 3), (2, 0, 4, 3, 1), (2, 1, 0, 3, 4), (2, 1, 0, 4, 3), (2, 1, 3, 0, 4), (2, 1, 3, 4, 0), (2, 1, 4, 0, 3), (2, 1, 4, 3, 0), (2, 3, 0, 1, 4), (2, 3, 0, 4, 1), (2, 3, 1, 0, 4), (2, 3, 1, 4, 0), (2, 3, 4, 0, 1), (2, 3, 4, 1, 0), (2, 4, 0, 1, 3), (2, 4, 0, 3, 1), (2, 4, 1, 0, 3), (2, 4, 1, 3, 0), (2, 4, 3, 0, 1), (2, 4, 3, 1, 0), (3, 0, 1, 2, 4), (3, 0, 1, 4, 2), (3, 0, 2, 1, 4), (3, 0, 2, 4, 1), (3, 0, 4, 1, 2), (3, 0, 4, 2, 1), (3, 1, 0, 2, 4), (3, 1, 0, 4, 2), (3, 1, 2, 0, 4), (3, 1, 2, 4, 0), (3, 1, 4, 0, 2), (3, 1, 4, 2, 0), (3, 2, 0, 1, 4), (3, 2, 0, 4, 1), (3, 2, 1, 0, 4), (3, 2, 1, 4, 0), (3, 2, 4, 0, 1), (3, 2, 4, 1, 0), (3, 4, 0, 1, 2), (3, 4, 0, 2, 1), (3, 4, 1, 0, 2), (3, 4, 1, 2, 0), (3, 4, 2, 0, 1), (3, 4, 2, 1, 0), (4, 0, 1, 2, 3), (4, 0, 1, 3, 2), (4, 0, 2, 1, 3), (4, 0, 2, 3, 1), (4, 0, 3, 1, 2), (4, 0, 3, 2, 1), (4, 1, 0, 2, 3), (4, 1, 0, 3, 2), (4, 1, 2, 0, 3), (4, 1, 2, 3, 0), (4, 1, 3, 0, 2), (4, 1, 3, 2, 0), (4, 2, 0, 1, 3), (4, 2, 0, 3, 1), (4, 2, 1, 0, 3), (4, 2, 1, 3, 0), (4, 2, 3, 0, 1), (4, 2, 3, 1, 0), (4, 3, 0, 1, 2), (4, 3, 0, 2, 1), (4, 3, 1, 0, 2), (4, 3, 1, 2, 0), (4, 3, 2, 0, 1), (4, 3, 2, 1, 0)]\n",
      "len(objTypeDict['Vehicles']['correspondence']):  120\n",
      "objTypeDict['Pedestrians']['count'] 2\n",
      "objTypeDict['Pedestrians']['correspondence'] [(0, 1), (1, 0)]\n",
      "sorted_types:  ['Vehicles', 'Pedestrians']\n",
      "sorted_types_nums:  [5, 2]\n",
      "num_identicals:  [2, 1]\n",
      "num_lastObjType_correspondence:  2\n",
      "num_iteration:  120\n",
      "lastObjType:  Pedestrians\n",
      "finalOutput:  [(0, 1, 0, 2, 3, 1, 4), (0, 1, 1, 2, 3, 0, 4), (0, 1, 0, 2, 4, 1, 3), (0, 1, 1, 2, 4, 0, 3), (0, 1, 0, 3, 2, 1, 4), (0, 1, 1, 3, 2, 0, 4), (0, 1, 0, 3, 4, 1, 2), (0, 1, 1, 3, 4, 0, 2), (0, 1, 0, 4, 2, 1, 3), (0, 1, 1, 4, 2, 0, 3), (0, 1, 0, 4, 3, 1, 2), (0, 1, 1, 4, 3, 0, 2), (0, 2, 0, 1, 3, 1, 4), (0, 2, 1, 1, 3, 0, 4), (0, 2, 0, 1, 4, 1, 3), (0, 2, 1, 1, 4, 0, 3), (0, 2, 0, 3, 1, 1, 4), (0, 2, 1, 3, 1, 0, 4), (0, 2, 0, 3, 4, 1, 1), (0, 2, 1, 3, 4, 0, 1), (0, 2, 0, 4, 1, 1, 3), (0, 2, 1, 4, 1, 0, 3), (0, 2, 0, 4, 3, 1, 1), (0, 2, 1, 4, 3, 0, 1), (0, 3, 0, 1, 2, 1, 4), (0, 3, 1, 1, 2, 0, 4), (0, 3, 0, 1, 4, 1, 2), (0, 3, 1, 1, 4, 0, 2), (0, 3, 0, 2, 1, 1, 4), (0, 3, 1, 2, 1, 0, 4), (0, 3, 0, 2, 4, 1, 1), (0, 3, 1, 2, 4, 0, 1), (0, 3, 0, 4, 1, 1, 2), (0, 3, 1, 4, 1, 0, 2), (0, 3, 0, 4, 2, 1, 1), (0, 3, 1, 4, 2, 0, 1), (0, 4, 0, 1, 2, 1, 3), (0, 4, 1, 1, 2, 0, 3), (0, 4, 0, 1, 3, 1, 2), (0, 4, 1, 1, 3, 0, 2), (0, 4, 0, 2, 1, 1, 3), (0, 4, 1, 2, 1, 0, 3), (0, 4, 0, 2, 3, 1, 1), (0, 4, 1, 2, 3, 0, 1), (0, 4, 0, 3, 1, 1, 2), (0, 4, 1, 3, 1, 0, 2), (0, 4, 0, 3, 2, 1, 1), (0, 4, 1, 3, 2, 0, 1), (1, 0, 0, 2, 3, 1, 4), (1, 0, 1, 2, 3, 0, 4), (1, 0, 0, 2, 4, 1, 3), (1, 0, 1, 2, 4, 0, 3), (1, 0, 0, 3, 2, 1, 4), (1, 0, 1, 3, 2, 0, 4), (1, 0, 0, 3, 4, 1, 2), (1, 0, 1, 3, 4, 0, 2), (1, 0, 0, 4, 2, 1, 3), (1, 0, 1, 4, 2, 0, 3), (1, 0, 0, 4, 3, 1, 2), (1, 0, 1, 4, 3, 0, 2), (1, 2, 0, 0, 3, 1, 4), (1, 2, 1, 0, 3, 0, 4), (1, 2, 0, 0, 4, 1, 3), (1, 2, 1, 0, 4, 0, 3), (1, 2, 0, 3, 0, 1, 4), (1, 2, 1, 3, 0, 0, 4), (1, 2, 0, 3, 4, 1, 0), (1, 2, 1, 3, 4, 0, 0), (1, 2, 0, 4, 0, 1, 3), (1, 2, 1, 4, 0, 0, 3), (1, 2, 0, 4, 3, 1, 0), (1, 2, 1, 4, 3, 0, 0), (1, 3, 0, 0, 2, 1, 4), (1, 3, 1, 0, 2, 0, 4), (1, 3, 0, 0, 4, 1, 2), (1, 3, 1, 0, 4, 0, 2), (1, 3, 0, 2, 0, 1, 4), (1, 3, 1, 2, 0, 0, 4), (1, 3, 0, 2, 4, 1, 0), (1, 3, 1, 2, 4, 0, 0), (1, 3, 0, 4, 0, 1, 2), (1, 3, 1, 4, 0, 0, 2), (1, 3, 0, 4, 2, 1, 0), (1, 3, 1, 4, 2, 0, 0), (1, 4, 0, 0, 2, 1, 3), (1, 4, 1, 0, 2, 0, 3), (1, 4, 0, 0, 3, 1, 2), (1, 4, 1, 0, 3, 0, 2), (1, 4, 0, 2, 0, 1, 3), (1, 4, 1, 2, 0, 0, 3), (1, 4, 0, 2, 3, 1, 0), (1, 4, 1, 2, 3, 0, 0), (1, 4, 0, 3, 0, 1, 2), (1, 4, 1, 3, 0, 0, 2), (1, 4, 0, 3, 2, 1, 0), (1, 4, 1, 3, 2, 0, 0), (2, 0, 0, 1, 3, 1, 4), (2, 0, 1, 1, 3, 0, 4), (2, 0, 0, 1, 4, 1, 3), (2, 0, 1, 1, 4, 0, 3), (2, 0, 0, 3, 1, 1, 4), (2, 0, 1, 3, 1, 0, 4), (2, 0, 0, 3, 4, 1, 1), (2, 0, 1, 3, 4, 0, 1), (2, 0, 0, 4, 1, 1, 3), (2, 0, 1, 4, 1, 0, 3), (2, 0, 0, 4, 3, 1, 1), (2, 0, 1, 4, 3, 0, 1), (2, 1, 0, 0, 3, 1, 4), (2, 1, 1, 0, 3, 0, 4), (2, 1, 0, 0, 4, 1, 3), (2, 1, 1, 0, 4, 0, 3), (2, 1, 0, 3, 0, 1, 4), (2, 1, 1, 3, 0, 0, 4), (2, 1, 0, 3, 4, 1, 0), (2, 1, 1, 3, 4, 0, 0), (2, 1, 0, 4, 0, 1, 3), (2, 1, 1, 4, 0, 0, 3), (2, 1, 0, 4, 3, 1, 0), (2, 1, 1, 4, 3, 0, 0), (2, 3, 0, 0, 1, 1, 4), (2, 3, 1, 0, 1, 0, 4), (2, 3, 0, 0, 4, 1, 1), (2, 3, 1, 0, 4, 0, 1), (2, 3, 0, 1, 0, 1, 4), (2, 3, 1, 1, 0, 0, 4), (2, 3, 0, 1, 4, 1, 0), (2, 3, 1, 1, 4, 0, 0), (2, 3, 0, 4, 0, 1, 1), (2, 3, 1, 4, 0, 0, 1), (2, 3, 0, 4, 1, 1, 0), (2, 3, 1, 4, 1, 0, 0), (2, 4, 0, 0, 1, 1, 3), (2, 4, 1, 0, 1, 0, 3), (2, 4, 0, 0, 3, 1, 1), (2, 4, 1, 0, 3, 0, 1), (2, 4, 0, 1, 0, 1, 3), (2, 4, 1, 1, 0, 0, 3), (2, 4, 0, 1, 3, 1, 0), (2, 4, 1, 1, 3, 0, 0), (2, 4, 0, 3, 0, 1, 1), (2, 4, 1, 3, 0, 0, 1), (2, 4, 0, 3, 1, 1, 0), (2, 4, 1, 3, 1, 0, 0), (3, 0, 0, 1, 2, 1, 4), (3, 0, 1, 1, 2, 0, 4), (3, 0, 0, 1, 4, 1, 2), (3, 0, 1, 1, 4, 0, 2), (3, 0, 0, 2, 1, 1, 4), (3, 0, 1, 2, 1, 0, 4), (3, 0, 0, 2, 4, 1, 1), (3, 0, 1, 2, 4, 0, 1), (3, 0, 0, 4, 1, 1, 2), (3, 0, 1, 4, 1, 0, 2), (3, 0, 0, 4, 2, 1, 1), (3, 0, 1, 4, 2, 0, 1), (3, 1, 0, 0, 2, 1, 4), (3, 1, 1, 0, 2, 0, 4), (3, 1, 0, 0, 4, 1, 2), (3, 1, 1, 0, 4, 0, 2), (3, 1, 0, 2, 0, 1, 4), (3, 1, 1, 2, 0, 0, 4), (3, 1, 0, 2, 4, 1, 0), (3, 1, 1, 2, 4, 0, 0), (3, 1, 0, 4, 0, 1, 2), (3, 1, 1, 4, 0, 0, 2), (3, 1, 0, 4, 2, 1, 0), (3, 1, 1, 4, 2, 0, 0), (3, 2, 0, 0, 1, 1, 4), (3, 2, 1, 0, 1, 0, 4), (3, 2, 0, 0, 4, 1, 1), (3, 2, 1, 0, 4, 0, 1), (3, 2, 0, 1, 0, 1, 4), (3, 2, 1, 1, 0, 0, 4), (3, 2, 0, 1, 4, 1, 0), (3, 2, 1, 1, 4, 0, 0), (3, 2, 0, 4, 0, 1, 1), (3, 2, 1, 4, 0, 0, 1), (3, 2, 0, 4, 1, 1, 0), (3, 2, 1, 4, 1, 0, 0), (3, 4, 0, 0, 1, 1, 2), (3, 4, 1, 0, 1, 0, 2), (3, 4, 0, 0, 2, 1, 1), (3, 4, 1, 0, 2, 0, 1), (3, 4, 0, 1, 0, 1, 2), (3, 4, 1, 1, 0, 0, 2), (3, 4, 0, 1, 2, 1, 0), (3, 4, 1, 1, 2, 0, 0), (3, 4, 0, 2, 0, 1, 1), (3, 4, 1, 2, 0, 0, 1), (3, 4, 0, 2, 1, 1, 0), (3, 4, 1, 2, 1, 0, 0), (4, 0, 0, 1, 2, 1, 3), (4, 0, 1, 1, 2, 0, 3), (4, 0, 0, 1, 3, 1, 2), (4, 0, 1, 1, 3, 0, 2), (4, 0, 0, 2, 1, 1, 3), (4, 0, 1, 2, 1, 0, 3), (4, 0, 0, 2, 3, 1, 1), (4, 0, 1, 2, 3, 0, 1), (4, 0, 0, 3, 1, 1, 2), (4, 0, 1, 3, 1, 0, 2), (4, 0, 0, 3, 2, 1, 1), (4, 0, 1, 3, 2, 0, 1), (4, 1, 0, 0, 2, 1, 3), (4, 1, 1, 0, 2, 0, 3), (4, 1, 0, 0, 3, 1, 2), (4, 1, 1, 0, 3, 0, 2), (4, 1, 0, 2, 0, 1, 3), (4, 1, 1, 2, 0, 0, 3), (4, 1, 0, 2, 3, 1, 0), (4, 1, 1, 2, 3, 0, 0), (4, 1, 0, 3, 0, 1, 2), (4, 1, 1, 3, 0, 0, 2), (4, 1, 0, 3, 2, 1, 0), (4, 1, 1, 3, 2, 0, 0), (4, 2, 0, 0, 1, 1, 3), (4, 2, 1, 0, 1, 0, 3), (4, 2, 0, 0, 3, 1, 1), (4, 2, 1, 0, 3, 0, 1), (4, 2, 0, 1, 0, 1, 3), (4, 2, 1, 1, 0, 0, 3), (4, 2, 0, 1, 3, 1, 0), (4, 2, 1, 1, 3, 0, 0), (4, 2, 0, 3, 0, 1, 1), (4, 2, 1, 3, 0, 0, 1), (4, 2, 0, 3, 1, 1, 0), (4, 2, 1, 3, 1, 0, 0), (4, 3, 0, 0, 1, 1, 2), (4, 3, 1, 0, 1, 0, 2), (4, 3, 0, 0, 2, 1, 1), (4, 3, 1, 0, 2, 0, 1), (4, 3, 0, 1, 0, 1, 2), (4, 3, 1, 1, 0, 0, 2), (4, 3, 0, 1, 2, 1, 0), (4, 3, 1, 1, 2, 0, 0), (4, 3, 0, 2, 0, 1, 1), (4, 3, 1, 2, 0, 0, 1), (4, 3, 0, 2, 1, 1, 0), (4, 3, 1, 2, 1, 0, 0)]\n",
      "240\n",
      "240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/simulators/carla/model.scenic:56: UserWarning: the \"carla\" package is not installed; will not be able to run dynamic simulations\n",
      "  warnings.warn('the \"carla\" package is not installed; '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scenic\n",
    "scenic_script = \"./examples/carla/ICCV_Scenic_Experiments/7_agent_scenario.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "x = generateObjectMatchingCorrespondenceSet(scenario, None)\n",
    "print(\"finalOutput: \", x)\n",
    "print(len(x))\n",
    "print(len(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Object Matching\n",
    "import math\n",
    "\n",
    "def conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    for obj_index in range(len(scenario.original_objects)):\n",
    "        obj = scenario.original_objects[obj_index]\n",
    "        for attribute_name in attributeList:\n",
    "            objType = findObjType(obj)\n",
    "            attr_label = extractLabelAttribute(label, obj_index, attribute_name, objType, \\\n",
    "                                               dataType, correspondence, egoObjIndex)\n",
    "            if isinstance(attr_label, (float, int)):\n",
    "                attr_label = Constant(attr_label)\n",
    "            obj_attr = getattr(obj, attribute_name)\n",
    "            obj_attr.conditionTo(attr_label)\n",
    "\n",
    "def satisfyHardConstraints(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType):\n",
    "    unconditionAllAttributes(scenario)\n",
    "    conditionAllAttributes(scenario, dictionary, label, attributeList, correspondence, egoObjIndex, dataType)\n",
    "    return scenario.checkRequirements()\n",
    "\n",
    "def validateLabel(scenario, label, dataType='carla', ego_visibleDistance = 50, ego_viewAngle = 360, \\\n",
    "                  smt_file_path='./test_smt_encoding.smt2', attributeList = ['position', 'heading'], \\\n",
    "                  debug = False):\n",
    "    #TODO: need to add object matching\n",
    "    \n",
    "    # Uncondition previously conditioned dependency objects\n",
    "    unconditionAllAttributes(scenario)\n",
    "    \n",
    "    # Initialize smt file, if exists\n",
    "    initializeSMTFile(smt_file_path)\n",
    "    \n",
    "    # Create Ego's VisibleRegion\n",
    "    cached_variables = {}\n",
    "#     if map_source == 'carla':\n",
    "#         cached_variables['network'] = Network.fromFile(map_path, None)\n",
    "#     elif map_source == 'nuScenes':\n",
    "#         raise NotImplementedError\n",
    "#     else:\n",
    "#          raise NotImplementedError\n",
    "    cached_variables['smt_file_path'] = smt_file_path\n",
    "    cached_variables['variables'] = []\n",
    "    (ego_x, ego_y) = label['EgoCar']['position']\n",
    "    label_ego_pos = Vector(ego_x, ego_y)\n",
    "    label_ego_heading = math.radians(label['EgoCar']['heading']+90)\n",
    "    regionAroundEgo = SectorRegion(label_ego_pos, ego_visibleDistance, label_ego_heading, \\\n",
    "                                    math.radians(ego_viewAngle))\n",
    "    cached_variables['regionAroundEgo'] = regionAroundEgo\n",
    "    cached_variables['regionAroundEgo_polygon'] = regionAroundEgo.polygon\n",
    "    dictionary = dependencyAnalysis(scenario, attributeList)\n",
    "    sortedDependencyList = sortDependency(dictionary, scenario)\n",
    "#     print(\"sortedDependencyList: \", sortedDependencyList)\n",
    "    \n",
    "    allObjCorrespondence = generateObjectMatchingCorrespondenceSet(scenario, label)\n",
    "    egoObjIndex = findEgoObjIndex(scenario)\n",
    "    \n",
    "    for correspondence in allObjCorrespondence:\n",
    "        failed = False\n",
    "        for jointlyDependentAttributeList in sortedDependencyList:\n",
    "#             print(\".........................validating : \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "            if validateLabelElement(scenario, cached_variables, jointlyDependentAttributeList, dictionary, \\\n",
    "                                            correspondence, egoObjIndex, dataType, debug):\n",
    "#                 print(\".........................valid attribute: \", str(jointlyDependentAttributeList)+\".......................\")\n",
    "                conditionAttributes(jointlyDependentAttributeList, dictionary, scenario, dataType, \\\n",
    "                                    correspondence, egoObjIndex, label)\n",
    "                resetDictionary(cached_variables, regionAroundEgo, smt_file_path)\n",
    "            else: # condition attributes in jointlyDependentAttributeList\n",
    "                print(\"NON-VALID ATTRIBUTES: \", jointlyDependentAttributeList)\n",
    "                failed = True\n",
    "                unconditionAllAttributes(scenario)\n",
    "                resetDictionary(cached_variables, regionAroundEgo, smt_file_path)\n",
    "                break\n",
    "    \n",
    "        ## Check Hard Constraint Satisfaction\n",
    "        if not failed and satisfyHardConstraints(scenario, dictionary, label, attributeList, \\\n",
    "                                                 correspondence, egoObjIndex, dataType):\n",
    "            return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scenic\n",
    "scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "\n",
    "directory = '/Users/edwardkim/Desktop/Scenic_Query/nuscenes_data/experiment_results'\n",
    "subject1 = 'experiment_result_JayShenoy'\n",
    "subject2 = 'experiment_result_TaeSung'\n",
    "subject3 = 'experiment_result_Xiangyu'\n",
    "scenario_list = ['scenario1','scenario2','scenario3','scenario4','scenario5']\n",
    "dir3 = os.path.join(directory, 'scenario1_intersection')\n",
    "# dir3 = os.path.join(directory, subject3, 'scenario3')\n",
    "filenames = [file for file in os.listdir(dir3) if file.endswith('.jpg')]\n",
    "img_name = filenames[0]\n",
    "label = nusc.get_img_data(img_name)\n",
    "ego_label = label['EgoCar']\n",
    "vehicles_label = label['Vehicles']\n",
    "pedestrians_label = label['Pedestrians']\n",
    "# print(ego_label)\n",
    "# print(vehicles_label)\n",
    "# print(pedestrians_label)\n",
    "count = 0\n",
    "# for file in filenames:\n",
    "file = 'n008-2018-08-31-11-19-57-0400__CAM_FRONT__1535728830362404.jpg'\n",
    "count += 1\n",
    "label = nusc.get_img_data(file)\n",
    "if not validateLabel(scenario, label, dataType='nuScenes', debug=True):\n",
    "    print(\"NON-VALID file: \", file)\n",
    "#     break\n",
    "else:\n",
    "    print(\"Valid \"+str(count)+\": \", file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Network.fromPickle('/Users/edwardkim/Desktop/Scenic_Query/Scenic/src/scenic/domains/driving/boston-network.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "label = nusc.get_img_data(file)\n",
    "pos = label['EgoCar']['position']\n",
    "print(pos)\n",
    "ego_pos = Point(pos[0],pos[1])\n",
    "ego_vec = Vector(pos[0],pos[1])\n",
    "\n",
    "for road in network.roads:\n",
    "    polygon = road.polygon\n",
    "    plt.plot(*polygon.exterior.xy, color='g')\n",
    "\n",
    "for road in network.intersections:\n",
    "    polygon = road.polygon\n",
    "    plt.plot(*polygon.exterior.xy, color='k')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "possibleRoads = []\n",
    "for road in network.roads:\n",
    "    polygon = road.polygon\n",
    "    if polygon.distance(ego_pos) < 200:\n",
    "        plt.plot(*polygon.exterior.xy, color='g')\n",
    "\n",
    "for road in network.intersections:\n",
    "    polygon = road.polygon\n",
    "    if polygon.distance(ego_pos) < 200:\n",
    "        if road.containsPoint(ego_vec):\n",
    "            plt.plot(*polygon.exterior.xy, color='r')\n",
    "        else:\n",
    "            plt.plot(*polygon.exterior.xy, color='k')\n",
    "        \n",
    "plt.show()\n",
    "\n",
    "# for road in network.intersections:\n",
    "#     if road.containsPoint(ego_vec):\n",
    "#         plt.plot(*polygon.exterior.xy, color='k')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scenic\n",
    "scenic_script = \"./examples/carla/ICCV_Human_Experiments/experiment1.scenic\"\n",
    "scenario = scenic.scenarioFromFile(scenic_script)\n",
    "# map_path = '/Users/edwardkim/Desktop/Scenic_Query/Scenic/tests/formats/opendrive/maps/CARLA/Town05.xodr'\n",
    "\n",
    "for i in range(1):\n",
    "    unconditionAllAttributes(scenario)\n",
    "    sample = scenario.generateForQuery(maxIterations = 4000, verbosity=0)\n",
    "    label, _ = sample\n",
    "    if not validateLabel(scenario, label, dataType='nuScenes', debug=False):\n",
    "        print(\"NOT VALID LABEL\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"label is valid: \", i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Car\" in str(scenario.original_objects[2]))\n",
    "# print(str(scenario.original_objects[0]).startswith(\"Car\"))\n",
    "# print(str(scenario.original_objects[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Issue1: ahead/behind, left/right of uses the same heading angle as the referenced\n",
    "        (1) As a result, position & heading are jointly dependent\n",
    "        ==> what if we do not allow joint dependency between position and heading?\n",
    "        This assumes that we can decouple joint dependency between the two, if exists.\n",
    "        Is this true? Yes\n",
    "        ==> Limitation: if many there are many jointly dependent features all at once, it may not be feasible to solve\n",
    "        \n",
    "        (2) an obj can have its position be dependent on its heading because its heading is the same as the \n",
    "        heading of another object to which the obj is depedent\n",
    "        ==> is this only an issue with ego? because the ordering of the objects \n",
    "        ==> ==> solution: just keep the original objects ordering\n",
    "\n",
    "Issue2: my assumption that jointly dependent and dependent relationships are disjoint is wrong\n",
    "        (e.g. dependencyAnalysisTest4.scenic)\n",
    "        ==> it's not possible to capture such case since the attribute contains the intermediate variable\n",
    "        ==> another ordering process needs to be done within jointly dependent features based on dependence relations\n",
    "\n",
    "Issue3: Need to check the case when multiple attributes are dependent on another attributes\n",
    "        (e.g. )\n",
    "        \n",
    "\n",
    "Sorting Approach\n",
    "Since the objects are listed in the order the scenario is written, \n",
    "the order in which SMT translation is to be done stays intact\n",
    "The only issue now is to determine joint dependency\n",
    "==> before adding to joint dependency, check whether the jointly dependent attribute is dependent on any of the\n",
    "other jointly dependent attributes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
